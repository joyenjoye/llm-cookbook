{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ff1e37-2662-434f-9388-7e5eec3869f4",
   "metadata": {},
   "source": [
    "<div class=\"toc\">\n",
    " <ul class=\"toc-item\">\n",
    "     <li><span><a href=\"#一、引言\" data-toc-modified-id=\"一、引言\">一、引言</a></span></li>\n",
    "     <li>\n",
    "         <span><a href=\"#二、工具调用代码示例\" data-toc-modified-id=\"二、工具调用代码示例\">二、工具调用代码示例</a></span>\n",
    "         <ul class=\"toc-item\">\n",
    "             <li><span><a href=\"##2.1 从 Python 函数定义工具接口\" data-toc-modified-id=\"2.1 从 Python 函数定义工具接口\">2.1 从 Python 函数定义工具接口</a></span></li>\n",
    "             <li><span><a href=\"##2.2 定义自动检索工具\" data-toc-modified-id=\"2.2 定义自动检索工具\">2.2 定义自动检索工具</a></span></li>\n",
    "             <li><span><a href=\"##2.3 综合的工具选择系统\" data-toc-modified-id=\"2.3 综合的工具选择系统\">2.3 综合的工具选择系统</a></span></li>\n",
    "             </ul>\n",
    "         </li>\n",
    "     <li><span><a href=\"#三、本章小结\" data-toc-modified-id=\"三、本章小结\">三、本章小结</a></span></li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56262ca4-0463-4c31-9f1b-fb80eaaa5f31",
   "metadata": {},
   "source": [
    "## 一、引言\n",
    "***\n",
    "\n",
    "LLMs 的优点之一是能够与外部环境交互并采取行动。为了实现这一目标，LLM 需要使用有效且可靠的接口，我们称之为**工具调用**。在基础的 RAG 管道中，LLMs 仅用于生成结果。之前 2. 路由查询引擎 Router Query Engine 教程已经向您展示了如何以略微更复杂的方式（router）使用 LLMs，即利用它来选择最佳的查询管道以回答用户的查询。这是工具调用的简化形式。\n",
    "\n",
    "在这个信息爆炸的时代，我们面临着一个前所未有的挑战：如何从海量数据中快速、准确地检索和处理信息。本教程正是为了应对这一挑战而设计的，它将引导我们进入一个由大语言模型（Large Language Models，LLMs）和工具调用（Tool Calling）技术共同构建的智能信息处理新世界。\n",
    "\n",
    "在本教程中，我们将探索一种革命性的方法，这种方法不仅能够让 LLMs 生成文本，还能使它们在决策过程中扮演更为关键的角色。想象一下，**一个系统能够理解您的查询，自动选择最合适的工具来处理问题，并准确地推断出需要传递给这些工具的参数**。这不再是科幻小说中的场景，而是我们即将揭开的技术现实。\n",
    "\n",
    "我们将从 RAG 管道的基础原理出发，逐步深入到更高级的工具调用概念。您将学习到如何定义工具接口，并通过 Python 函数的签名自动推断参数，这是 LlamaIndex 索引抽象的核心。我们将通过实际的代码示例，展示如何将这些工具传递给 LLM，并利用 predict_and_call 函数来实现智能决策和执行。\n",
    "\n",
    "教程的重点之一是展示 LLMs 如何与向量数据库交互，通过元数据过滤器来优化搜索结果，从而提供更精确的信息检索。这不仅提高了效率，还极大地增强了用户体验。随着代码示例的深入，我们将构建一个复杂的智能体层，它将展示 LLMs 在选择工具和推断参数方面的高级能力。最终，我们将整合所有这些技术，构建一个完整的工具选择系统，它能够理解复杂的用户查询，并提供精确、有用的答案。结果是用户可以提出更多问题，并**通过工具调用获得比标准 RAG 技术更精确的结果**。\n",
    "\n",
    "本教程不仅适合那些对大语言模型和 LLM-based Agent 感兴趣的学生和专业人士，也适合任何希望在信息检索和处理领域保持领先地位的人。让我们一起开启这段激动人心的学习之旅，探索如何利用 LLMs 和工具调用技术，构建下一代 Agentic RAG 系统。那么，让我们开始编码吧~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4ed33-a4a4-4d97-9589-ecf8252f365e",
   "metadata": {},
   "source": [
    "## 二、工具调用代码示例\n",
    "***\n",
    "\n",
    "与之前的教程类似，我们首先要设置 `OpenAI API KEY`。另外，我们还将设置并导入 `Nest AsyncIO` 模块。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574a5b90-8e14-4f88-95f0-b6f1e8180bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fa7e2-9763-45a5-94d2-42d9484de817",
   "metadata": {},
   "source": [
    "下面两行代码通过**启用对嵌套异步事件循环的支持**，极大地提高了在特定场景下（如 Jupyter Notebook）处理异步操作的可行性和便捷性。\n",
    "\n",
    "**解决的问题**：通常，在 Python 中，`asyncio` 模块不允许在已经运行的事件循环中再启动另一个事件循环。这是因为 `asyncio` 设计上假设每个线程只会有一个正在运行的事件循环。然而，在某些应用场景，特别是像 Jupyter Notebook 这样的交互式环境中，已经有一个运行中的事件循环了（由于 notebook 自身的需求）。如果用户尝试创建并运行另一个事件循环（例如，使用 `asyncio.run()` ），将会抛出异常。这给基于异步编程模型开发交互式应用带来了不便。因此，`nest_asyncio` 库正是为了解决这一限制而诞生。（LlamaIndex 为了实现高效加载和处理数据，有些功能可能使用了异步编程优化 I/O 操作）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bfb081-f5a2-470d-a10f-64f4fac7f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2ba3f-1a6b-47e5-a009-e5390bd3065e",
   "metadata": {},
   "source": [
    "### 2.1 从 Python 函数定义工具接口"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7a91f-4064-4bce-8d2e-3ce1ecaca99d",
   "metadata": {},
   "source": [
    "接下来，我们将进行工具调用的基本回顾和介绍。我们将向您展示**如何从 Python 函数定义工具接口**，LLM 将使用 LlamaIndex 抽象从 **Python 函数的签名**自动推断参数。\n",
    "\n",
    "为了说明这一点，让我们首先定义两个简单的计算器函数来向您展示工具调用是如何工作的。我们将定义一个 add 函数和一个 mystery 函数。\n",
    "\n",
    "LlamaIndex 中的核心抽象是函数工具（**FunctionTool**）。**此函数工具会包装您提供给它的任何具体的 Python 函数**，所以，我们看到函数工具接受了这里定义的 add 函数以及一个 mystery 函数（也就是 x + y 乘以 x + y）。您可以看到 add 和 mystery 都有 x 和 y 变量的**类型注释**，还有文档字符串（**docstring**）。这不仅仅是为了编程规范目的，这实际上很重要，因为这些东西将被用作 **LLM 的提示（Prompts）**。目前，LlamaIndex 的函数工具已经与许多 LLM 提供商（包括 OpenAI）的**函数调用功能**进行了原生集成。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a85c750-2568-4c97-a055-f49caf3ee354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int: \n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2092d7-4d01-4c18-9306-2c77a188e9b9",
   "metadata": {},
   "source": [
    "要将工具传递给 LLM，您必须导入 LLM 模块，然后调用 **predict_and_call**。下面的代码片段显式导入了 OpenAI 模块，您会看到模型是 **gpt-3.5-turbo**，然后我们**在 LLM 之上调用 predict_and_call 函数**。\n",
    "\n",
    "predict_and_call 函数的作用是接受一组工具以及**输入提示字符串或一系列聊天消息**，然后它既能够决定要调用的工具，也能够调用工具本身，并返回最终的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a521508-7900-465f-9695-471dfd08893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "========================\n",
      "121 <class 'llama_index.core.chat_engine.types.AgentChatResponse'>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool], \n",
    "    \"Tell me the output of the mystery function on 2 and 9\", \n",
    "    verbose=True\n",
    ")\n",
    "print(\"=\" * 24)\n",
    "print(str(response), type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3526ad69-7f82-4c18-aedb-f69f873ac12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "========================\n",
      "121 <class 'llama_index.core.chat_engine.types.AgentChatResponse'>\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"将两个整数相加。\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int: \n",
    "    \"\"\"在两个数字之上运行的神秘函数。\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool], \n",
    "    \"告诉我 mystery 函数对 2 与 9 输出的结果\",\n",
    "    verbose=True\n",
    ")\n",
    "print(\"=\" * 24)\n",
    "print(str(response), type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e5c49-8784-4882-8011-3cf4c583e420",
   "metadata": {},
   "source": [
    "这里我们看到了调用函数 mystery 的中间步骤。函数传入参数：x 等于 2，y 等于 9。所以我们看到，代码实现调用了正确的工具，也推断出了正确的参数，输出是 121，11 乘以 11 是 121，所以我们得到了正确的答案。但请注意，这个简单的示例实际上是路由（router）的扩展版本。**LLM 不仅选择合适的工具，还要决定给工具给予什么参数**。\n",
    "\n",
    "下面的 2.2 定义自动检索工具小节，让我们使用这个关键概念在向量搜索之上定义一个稍微复杂一点的智能体层。**LLM 不仅可以选择向量搜索，我们还可以让它推断元数据过滤器**，这是一个结构化的标签列表，有助于返回一组更精确的搜索结果。我们将使用与前面相同的论文 MetaGPT，这次让我们关注节点本身，或者块，因为我们将查看附加到这些块的实际元数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e948754-315e-4e54-9a12-1b054d6678db",
   "metadata": {},
   "source": [
    "### 2.2 定义自动检索工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31316db-e97a-4743-8ee3-fa848c138c09",
   "metadata": {},
   "source": [
    "加载数据。下载运行代码所需的 **MetaGPT 论文** PDF：\n",
    "\n",
    "- 直接访问论文链接并下载：https://openreview.net/forum?id=VtmBAGCN7o ，然后将 PDF 文件放置在代码目录下。\n",
    "\n",
    "- 或者在 jupyter notebook 中直接运行：!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c80324-fedc-49f6-a82e-f7de73022a1d",
   "metadata": {},
   "source": [
    "下面这行代码的功能是从给定的 URL 下载一个 PDF 文档，并将其以 \"metagpt.pdf\" 为名保存到当前工作目录下。\n",
    "\n",
    "- `!`：这个符号通常在 Jupyter Notebook 环境中用来执行系统命令。\n",
    "\n",
    "- `wget`：这是实际执行下载操作的命令行工具。\n",
    "\n",
    "- `\"https://openreview.net/pdf?id=VtmBAGCN7o\"`：这是你想要下载的论文 PDF 的 URL。\n",
    "\n",
    "- `-O metagpt.pdf`：这个选项指定了下载文件的本地保存名称。`-O`（大写字母 O）后面跟着的 `metagpt.pdf` 是你希望保存下载文件时使用的名称。如果不使用 `-O` 选项，`wget` 会使用 URL 中最后一部分作为文件名来保存下载内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b09ebfe-b78c-457c-bba7-698f55e6eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-01 21:55:24--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16911937 (16M) [application/pdf]\n",
      "Saving to: ‘metagpt.pdf’\n",
      "\n",
      "metagpt.pdf         100%[===================>]  16.13M  34.9KB/s    in 6m 52s  \n",
      "\n",
      "2024-06-01 22:02:17 (40.1 KB/s) - ‘metagpt.pdf’ saved [16911937/16911937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8e2c44-0335-4d49-a2d8-8c113a5a7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 加载文件。使用 LlamaIndex 中的简单目录阅读器来加载此 pdf 文件的解析表示。\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847055d0-5590-4b05-82ce-8df040e74c34",
   "metadata": {},
   "source": [
    "这里的每个节点都代表一个块，让我们来看看一个示例块的内容。我们来看看第一个块的内容，通过执行 `node.getContent` 来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a91323b-8fe4-4e07-b9ae-177edf6c409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# 使用句子分割器将这些文档分割成一组偶数块，块大小为 1024。\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885bb7e-460c-4219-8db2-2b1cec8c11cd",
   "metadata": {},
   "source": [
    "我们将元数据模式设置为 `all`，这是一个特殊的设置，实际上不仅可以打印节点本身的内容，还可以打印附加到文档的元数据，这些元数据将传播到每个节点。结果打印如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933122bc-74d7-4d43-ac92-5c4cfd3e37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-06-01\n",
      "last_modified_date: 2024-06-01\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d15db-89f5-4193-8b9b-20de80fb730d",
   "metadata": {},
   "source": [
    "在这里我们看到，一旦我们打印出来，我们不仅得到了论文首页的解析表示，我们还可以看到**附加在顶部的元数据**。所以这包括：取值为 1 的页标签、**文件名（metagpt.pdf）、文件路径、文件类型、文件大小以及创建和结束日期**。\n",
    "\n",
    "此外，我们要特别注意页面标签。因为，例如，如果我们实际进入并尝试不同的节点，我们会看到我们实际上得到了不同的页码。所以我们实际上给每个块都添加了**页码注释**。接下来，**我们将在这些节点上定义一个向量存储索引**。这将基本上在这些节点上构建 RAG 索引管道。它会为每个节点添加一个嵌入，并返回一个查询引擎。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f73540-4766-4678-8b20-c0ee3bb1680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436546c-7c31-4bed-8cf4-4a0840289183",
   "metadata": {},
   "source": [
    "我们实际上可以尝试通过元数据过滤器查询此 RAG 管道，只是为了向您展示元数据过滤的工作原理。因此，我们导入这个名为 `MetadataFilters` 的对象，然后我们只需指定一个过滤器，其中页面标签的值设置 \"2\"；另外，similarity_top_k 也等于 2。\n",
    "\n",
    "因此，我们将其定义为查询引擎，并且我们查询 MetaGPT 论文中的一些高水平结果。如果我们观察一下源节点，一旦我们运行它，我们查询到 MetaGPT 的一些高水平结果。当我们收到响应时，我们首先看一下响应字符串，它概述了 MetaGPT 的总体结果。但至关重要的是，我们将查看页码。我们迭代源节点时，实际上可以打印出**附加到这些源节点的元数据**。我们看到这里的页面标签等于 \"2\"。因此我们观察到它能够正确过滤页码，**仅将搜索限制为页面标签等于 2 的页面**。这说明我们的查询引擎很聪明，它知道我们只想看标签为 \"2\" 的论文页面的信息。这样，我们就不会被其他不相关的页面干扰，可以更快地找到我们想要的答案。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3bbefb1-9d59-44c6-a505-5e8ab8e4f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}       # 根据页码过滤\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are some high-level results of MetaGPT?\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830e928c-d2ee-42b7-92ca-cac5f72e0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some high-level results of MetaGPT include achieving a new state-of-the-art in code generation benchmarks with 85.9% and 87.7% in Pass@1, outperforming other popular frameworks like AutoGPT, LangChain, AgentVerse, and ChatDev. Additionally, MetaGPT excels in handling higher levels of software complexity and providing extensive functionality, as evidenced by achieving a 100% task completion rate in experimental evaluations.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350dbfe4-9255-4016-8d0a-eac1fdb2cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c825b2cf-a788-4d9d-8a52-45c4f526b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"MetaGPT 取得了哪些高水平的结果？\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d214011c-9f3c-40f7-8b10-7c670782f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaGPT在代码生成基准测试中取得了85.9%和87.7%的一级通过率，超越了其他流行的框架，如AutoGPT，LangChain，AgentVerse和ChatDev。此外，在处理更高级别的软件复杂性和提供广泛功能方面，MetaGPT也表现出色。\n",
      "----------------------------------------------------------------------------------------\n",
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "print(str(response))\n",
    "print(\"-\" * 88)\n",
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306807f6-c383-4d2b-91ac-1cb989cc7578",
   "metadata": {},
   "source": [
    "本教程的最后一节将这个整体检索工具包装成一个函数。这个函数接受查询字符串和页码作为过滤器。**LLM 实际上可以推断要过滤用户查询的页码，而不是让用户手动指定元数据过滤器**。\n",
    "\n",
    "这里需要注意的是，元数据其实不仅限于页码。**您可以通过 LlamaIndex 抽象定义任何想要的元数据**，如节 IDs、页眉、页脚或其他任何内容。使用许多元数据过滤器的能力在 GPT-4 等更好的大语言模型中尤为突出，因此我们强烈建议读者自行实践一下。\n",
    "\n",
    "这里我们将定义一个封装它的 Python 函数。我们定义一个名为 **vector_query** 的函数，它接受查询和页码。这允许您对索引执行向量搜索，并指定页码作为元数据过滤器。最后，我们定义了一个向量查询 FunctionTool.from_defaults。因此，我们将 vector_query 函数传递到向量查询工具中，这使得我们可以将其与语言模型一起使用。\n",
    "\n",
    "因此，让我们借助 gpt-3.5-turbo 调用此工具。我们会发现 **LLM 能够推断字符串以及元数据过滤器**。我们在向量查询工具上进行了 predict_and_call，并提示了同样的问题：如第二页所述的 MetaGPT 的高水平结果。在这里我们看到 LLM 能够制定正确的查询（MetaGPT 的高水平结果），以及指定页码（取值为 \"2\"）。结果是我们得到了正确的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63594a7-46ff-47b9-8f68-517e6a502ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "def vector_query(query: str, page_number: int) -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "\n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (int): Filter by set of pages. Leave BLANK if we want to perform a vector search over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "    \"\"\"\n",
    "    print(page_number, type(page_number))\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": str(page_number)}]\n",
    "    print(metadata_dicts)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19a31a3-22c3-4fca-ac32-ff3e3d91cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 2, \"query\": \"high-level results of MetaGPT\"}\n",
      "2 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '2'}]\n",
      "=== Function Output ===\n",
      "MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It stands out in handling higher levels of software complexity and offering extensive functionality. In experimental evaluations, MetaGPT achieves a 100% task completion rate, demonstrating robustness and efficiency in terms of time and token costs.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc3418a-021b-4eaa-b1d6-57e0b279a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 2, \"query\": \"MetaGPT \\u7684\\u9ad8\\u6c34\\u5e73\\u7ed3\\u679c\"}\n",
      "2 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '2'}]\n",
      "=== Function Output ===\n",
      "MetaGPT 在代码生成基准测试中取得了新的技术水平，Pass@1 分别为 85.9% 和 87.7%，在处理更高级别的软件复杂性和提供广泛功能方面表现出色。在实验评估中，MetaGPT 实现了 100% 的任务完成率，展示了设计的稳健性和效率。\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "def vector_query(query: str, page_number: int) -> str:\n",
    "    \"\"\"对索引进行向量搜索。\n",
    "\n",
    "    query (str)：要进行嵌入的字符串查询。\n",
    "    page_numbers (int)：按页面集过滤。如果要在所有页面上进行向量搜索，则留空。否则，按指定的页面集过滤。\n",
    "\n",
    "    \"\"\"\n",
    "    print(page_number, type(page_number))\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": str(page_number)}]\n",
    "    print(metadata_dicts)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"第 2 页中描述的 MetaGPT 的高水平结果是什么？请用中文回答。\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f2e18-fc7a-476f-a344-4c4e0aea86bb",
   "metadata": {},
   "source": [
    "我们可以快速验证源节点，可以看到源节点的页面标签，有一个返回的源节点，它的页面标签是 \"2\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c538c019-089e-45fb-93a2-d419e3a1bfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2984818-d4fe-4f5a-8094-461a00b32b39",
   "metadata": {},
   "source": [
    "### 2.3 综合的工具选择系统"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd826632-9b6b-48bf-b49b-82a60e77a0c3",
   "metadata": {},
   "source": [
    "最后，我们可以从 2. 路由查询引擎 Router Query Engine 教程中的 router 示例中引入摘要工具，并将其与向量检索工具有机结合起来，创建这个综合的工具选择系统。所以，下面这段代码只是在相同的节点集上设置了一个摘要索引，并用一个摘要工具将其包装起来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18186ba-9cf2-486a-ab24-3777ef0e6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4719ad-66fb-4558-a68a-121cfe774e13",
   "metadata": {},
   "source": [
    "现在我们再次尝试工具调用。这样一来，**LLM 要做的任务略有提高难度**，它不仅要实际选择正确的工具，还要推断函数参数。我们询问论文第 8 页上 MetaGPT 与 ChatDev 的比较情况。我们看到它实际上还是调用了一个向量工具，页码等于 \"8\"，而且它能够给出正确的答案。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c6d1d3c-2116-4ea2-99cb-2a3a2975246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 8, \"query\": \"MetaGPT comparisons with ChatDev\"}\n",
      "8 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '8'}]\n",
      "=== Function Output ===\n",
      "MetaGPT outperforms ChatDev on the SoftwareDev dataset in various metrics. For example, MetaGPT achieves a higher score in executability, takes less time for software generation, uses more tokens but requires fewer tokens to generate one line of code compared to ChatDev. Additionally, MetaGPT demonstrates better performance in code statistics and human revision cost when compared to ChatDev.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c573e-f0d1-4569-ad47-fbad879adefb",
   "metadata": {},
   "source": [
    "我们还可以通过打印出来源节点来验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03154b63-3c04-409a-bbbd-d157db4415a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7716b78f-e4cc-4688-b51b-fa47dd68e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 8, \"query\": \"MetaGPT \\u4e0e ChatDev \\u7684\\u5bf9\\u6bd4\\u5206\\u6790\\u7ed3\\u679c\"}\n",
      "8 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '8'}]\n",
      "=== Function Output ===\n",
      "MetaGPT 在软件开发数据集中几乎在所有指标上均优于 ChatDev。例如，在可执行性方面，MetaGPT 获得了3.75的分数，接近4（完美）。此外，MetaGPT 生成一行代码所需的时间更短（503秒），明显少于 ChatDev。考虑到代码统计和人工修订成本，MetaGPT 也明显优于 ChatDev。虽然 MetaGPT 需要更多的标记（24,613或31,255比19,292多），但只需要126.5/124.3个标记来生成一行代码。相比之下，ChatDev 使用了248.9个标记。这些结果突显了在多个代理之间的协作中 SOP 的好处。\n",
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"如果您想了解 MetaGPT 的概要，这个工具会很有用。\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"第 8 页描述的 MetaGPT 与 ChatDev 的对比分析结果是什么？必须用中文回答。\", \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dba95-d0c5-432b-9217-515dab13f38d",
   "metadata": {},
   "source": [
    "最后，我们可以问一个问题，即**这篇论文的摘要是什么**，以显示 LLM 在必要时仍然能够选择摘要工具。我们看到它给出了正确的回应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29c21c9f-9a84-4690-8a0c-8e82c4ef2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"Summary of the MetaGPT paper\"}\n",
      "=== Function Output ===\n",
      "The MetaGPT paper introduces a meta-programming framework that utilizes Standardized Operating Procedures (SOPs) to enhance multi-agent systems based on Large Language Models (LLMs). It focuses on role specialization, structured communication interfaces, and executable feedback mechanisms to improve code generation quality during runtime. The framework involves agents like Product Managers, Architects, Engineers, and QA Engineers, each contributing specialized outputs to efficiently complete software development tasks. Additionally, it introduces the concept of AgentStore for creating and developing agents within the framework. The paper discusses the transformation of abstract requirements into detailed software designs, emphasizing the importance of structured messaging and feedback mechanisms. It addresses challenges such as reducing code hallucinations, utilizing context efficiently, and managing information overload. The system prioritizes user data privacy and security by operating locally, with open-source options available for backends. Ethical considerations like skill obsolescence, transparency, and privacy are also touched upon.\n"
     ]
    }
   ],
   "source": [
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What is a summary of the MetaGPT paper?\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7153e63-5da6-49f2-a144-d684b38963fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"MetaGPT\"}\n",
      "=== Function Output ===\n",
      "MetaGPT is a meta-programming framework that enhances problem-solving capabilities in multi-agent systems based on Large Language Models (LLMs). It incorporates role specialization, structured communication interfaces, and efficient sharing mechanisms to facilitate collaboration among agents. MetaGPT also utilizes an executable feedback mechanism to improve code generation quality during runtime. In experiments, MetaGPT has shown state-of-the-art performance on various benchmarks, outperforming other frameworks in tasks like code generation and software development. Additionally, MetaGPT is a framework that utilizes natural language programming to generate software applications based on provided prompts and requirements. It simplifies the process of transforming abstract requirements into detailed class and function designs through a specialized division of labor and standard operating procedures workflow. MetaGPT has been shown to outperform other models in terms of generating executable code, with a focus on structured messaging and feedback mechanisms to enhance communication and code execution. The framework also addresses challenges such as efficiently using context, reducing hallucinations in code generation, and managing information overload through a global message pool and subscription mechanism. Furthermore, MetaGPT emphasizes transparency, accountability, privacy, and data security, operating locally to ensure user data privacy and security.\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"如果您想了解 MetaGPT 的概要，这个工具会很有用。\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 发现使用 LlamaIndex 框架，即使是中文 Prompt，仍可能出现不遵循指令的情况。多次调试，输出结果仍是英文。\n",
    "# 因此，感兴趣的读者可以换一篇中文的论文 PDF 来做实验！\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"用中文输出 MetaGPT 论文的概要。\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a3ed5-1123-401c-9413-bfaf86f26415",
   "metadata": {},
   "source": [
    "## 三、本章小结\n",
    "***\n",
    "\n",
    "🧍🐒🤖 人与大多数动物的根本区别在于人能制造和使用工具。同样地，智能体也能利用各种外部工具来实现功能扩展和效率提升。\n",
    "\n",
    "在本教程中，我们展示了如何使用 LLM 来选择要执行的函数，并推断要传递给函数的参数。通过工具调用，LLM 不仅能够选择合适的工具，还能决定要给工具什么参数。这使得用户能够提出更多问题，并通过工具调用获得比标准 RAG 技术更精确的结果。\n",
    "\n",
    "教程中还展示了如何在向量搜索之上定义一个稍微复杂一点的智能体层。LLM 可以选择向量搜索，并推断元数据过滤器，以返回更精确的搜索结果。最后，我们展示了如何将整体检索工具封装成一个函数，使 LLM 能够推断用户查询的元数据过滤器。而且通过 LlamaIndex 索引抽象，我们还可以定义各种元数据过滤器，如章节 IDs、页码、页眉、页脚等。\n",
    "\n",
    "✨️🎉🚀 那么，**3. 工具调用 Tool Calling** 就到这里啦~ ✨️🎉🚀 \n",
    "\n",
    "🤖 下一章 **4. Building an Agent Reasoning Loop**，我们将向您展示如何构建智能体推理闭环！🤖"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
