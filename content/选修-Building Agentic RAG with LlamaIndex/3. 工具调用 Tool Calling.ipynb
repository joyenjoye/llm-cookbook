{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ff1e37-2662-434f-9388-7e5eec3869f4",
   "metadata": {},
   "source": [
    "<div class=\"toc\">\n",
    " <ul class=\"toc-item\">\n",
    "     <li><span><a href=\"#ä¸€ã€å¼•è¨€\" data-toc-modified-id=\"ä¸€ã€å¼•è¨€\">ä¸€ã€å¼•è¨€</a></span></li>\n",
    "     <li>\n",
    "         <span><a href=\"#äºŒã€å·¥å…·è°ƒç”¨ä»£ç ç¤ºä¾‹\" data-toc-modified-id=\"äºŒã€å·¥å…·è°ƒç”¨ä»£ç ç¤ºä¾‹\">äºŒã€å·¥å…·è°ƒç”¨ä»£ç ç¤ºä¾‹</a></span>\n",
    "         <ul class=\"toc-item\">\n",
    "             <li><span><a href=\"##2.1 ä» Python å‡½æ•°å®šä¹‰å·¥å…·æ¥å£\" data-toc-modified-id=\"2.1 ä» Python å‡½æ•°å®šä¹‰å·¥å…·æ¥å£\">2.1 ä» Python å‡½æ•°å®šä¹‰å·¥å…·æ¥å£</a></span></li>\n",
    "             <li><span><a href=\"##2.2 å®šä¹‰è‡ªåŠ¨æ£€ç´¢å·¥å…·\" data-toc-modified-id=\"2.2 å®šä¹‰è‡ªåŠ¨æ£€ç´¢å·¥å…·\">2.2 å®šä¹‰è‡ªåŠ¨æ£€ç´¢å·¥å…·</a></span></li>\n",
    "             <li><span><a href=\"##2.3 ç»¼åˆçš„å·¥å…·é€‰æ‹©ç³»ç»Ÿ\" data-toc-modified-id=\"2.3 ç»¼åˆçš„å·¥å…·é€‰æ‹©ç³»ç»Ÿ\">2.3 ç»¼åˆçš„å·¥å…·é€‰æ‹©ç³»ç»Ÿ</a></span></li>\n",
    "             </ul>\n",
    "         </li>\n",
    "     <li><span><a href=\"#ä¸‰ã€æœ¬ç« å°ç»“\" data-toc-modified-id=\"ä¸‰ã€æœ¬ç« å°ç»“\">ä¸‰ã€æœ¬ç« å°ç»“</a></span></li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56262ca4-0463-4c31-9f1b-fb80eaaa5f31",
   "metadata": {},
   "source": [
    "## ä¸€ã€å¼•è¨€\n",
    "***\n",
    "\n",
    "LLMs çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯èƒ½å¤Ÿä¸å¤–éƒ¨ç¯å¢ƒäº¤äº’å¹¶é‡‡å–è¡ŒåŠ¨ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼ŒLLM éœ€è¦ä½¿ç”¨æœ‰æ•ˆä¸”å¯é çš„æ¥å£ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º**å·¥å…·è°ƒç”¨**ã€‚\n",
    "\n",
    "åœ¨åŸºç¡€çš„ RAG ç®¡é“ä¸­ï¼ŒLLMs ä»…ç”¨äºç”Ÿæˆç»“æœã€‚2. è·¯ç”±æŸ¥è¯¢å¼•æ“ Router Query Engine æ•™ç¨‹å·²ç»å‘æ‚¨å±•ç¤ºäº†å¦‚ä½•ä»¥ç•¥å¾®æ›´å¤æ‚çš„æ–¹å¼ä½¿ç”¨ LLMsï¼ˆrouterï¼‰ï¼Œå³åˆ©ç”¨å®ƒæ¥é€‰æ‹©æœ€ä½³çš„æŸ¥è¯¢ç®¡é“ä»¥å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ã€‚è¿™æ˜¯å·¥å…·è°ƒç”¨çš„ç®€åŒ–å½¢å¼ã€‚åœ¨æœ¬ç« æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•é«˜æ•ˆä½¿ç”¨ LLMï¼Œ**ä¸ä»…æ­£ç¡®é€‰æ‹©è¦æ‰§è¡Œçš„å‡½æ•°ï¼Œè¿˜è¦æ¨æ–­è¦ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°**ã€‚è¿™ä½¿å¾— LLM èƒ½å¤Ÿç†è§£å¦‚ä½•ä½¿ç”¨å‘é‡æ•°æ®åº“ï¼Œè€Œä¸ä»…ä»…æ˜¯è·å–å…¶è¾“å‡ºã€‚\n",
    "\n",
    "ç»“æœæ˜¯ç”¨æˆ·å¯ä»¥æå‡ºæ›´å¤šé—®é¢˜ï¼Œå¹¶**é€šè¿‡å·¥å…·è°ƒç”¨è·å¾—æ¯”æ ‡å‡† RAG æŠ€æœ¯æ›´ç²¾ç¡®çš„ç»“æœ**ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬å¼€å§‹ç¼–ç å§~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4ed33-a4a4-4d97-9589-ecf8252f365e",
   "metadata": {},
   "source": [
    "## äºŒã€å·¥å…·è°ƒç”¨ä»£ç ç¤ºä¾‹\n",
    "***\n",
    "\n",
    "ä¸ä¹‹å‰ç±»ä¼¼ï¼Œæˆ‘ä»¬é¦–å…ˆè¦è®¾ç½® `OpenAI API KEY`ã€‚æˆ‘ä»¬è¿˜å°†è®¾ç½®å¹¶å¯¼å…¥ `Nest AsyncIO` æ¨¡å—ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574a5b90-8e14-4f88-95f0-b6f1e8180bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fa7e2-9763-45a5-94d2-42d9484de817",
   "metadata": {},
   "source": [
    "ä¸‹é¢ä¸¤è¡Œä»£ç é€šè¿‡**å¯ç”¨å¯¹åµŒå¥—å¼‚æ­¥äº‹ä»¶å¾ªç¯çš„æ”¯æŒ**ï¼Œæå¤§åœ°æé«˜äº†åœ¨ç‰¹å®šåœºæ™¯ä¸‹ï¼ˆå¦‚ Jupyter Notebookï¼‰å¤„ç†å¼‚æ­¥æ“ä½œçš„å¯è¡Œæ€§å’Œä¾¿æ·æ€§ã€‚\n",
    "\n",
    "**è§£å†³çš„é—®é¢˜**ï¼šé€šå¸¸ï¼Œåœ¨ Python ä¸­ï¼Œ`asyncio` æ¨¡å—ä¸å…è®¸åœ¨å·²ç»è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­å†å¯åŠ¨å¦ä¸€ä¸ªäº‹ä»¶å¾ªç¯ã€‚è¿™æ˜¯å› ä¸º `asyncio` è®¾è®¡ä¸Šå‡è®¾æ¯ä¸ªçº¿ç¨‹åªä¼šæœ‰ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ã€‚ç„¶è€Œï¼Œåœ¨æŸäº›åº”ç”¨åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯åƒ Jupyter Notebook è¿™æ ·çš„äº¤äº’å¼ç¯å¢ƒä¸­ï¼Œå·²ç»æœ‰ä¸€ä¸ªè¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯äº†ï¼ˆç”±äº notebook è‡ªèº«çš„éœ€æ±‚ï¼‰ã€‚å¦‚æœç”¨æˆ·å°è¯•åˆ›å»ºå¹¶è¿è¡Œå¦ä¸€ä¸ªäº‹ä»¶å¾ªç¯ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨ `asyncio.run()` ï¼‰ï¼Œå°†ä¼šæŠ›å‡ºå¼‚å¸¸ã€‚è¿™ç»™åŸºäºå¼‚æ­¥ç¼–ç¨‹æ¨¡å‹å¼€å‘äº¤äº’å¼åº”ç”¨å¸¦æ¥äº†ä¸ä¾¿ã€‚å› æ­¤ï¼Œ`nest_asyncio` åº“æ­£æ˜¯ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶è€Œè¯ç”Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bfb081-f5a2-470d-a10f-64f4fac7f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2ba3f-1a6b-47e5-a009-e5390bd3065e",
   "metadata": {},
   "source": [
    "### 2.1 ä» Python å‡½æ•°å®šä¹‰å·¥å…·æ¥å£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7a91f-4064-4bce-8d2e-3ce1ecaca99d",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿›è¡Œå·¥å…·è°ƒç”¨çš„åŸºæœ¬å›é¡¾å’Œä»‹ç»ã€‚æˆ‘ä»¬å°†å‘æ‚¨å±•ç¤º**å¦‚ä½•ä» Python å‡½æ•°å®šä¹‰å·¥å…·æ¥å£**ï¼ŒLLM å°†ä½¿ç”¨ LlamaIndex æŠ½è±¡ä» **Python å‡½æ•°çš„ç­¾å**è‡ªåŠ¨æ¨æ–­å‚æ•°ã€‚\n",
    "\n",
    "ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸¤ä¸ªç®€å•çš„è®¡ç®—å™¨å‡½æ•°æ¥å‘æ‚¨å±•ç¤ºå·¥å…·è°ƒç”¨æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ª add å‡½æ•°å’Œä¸€ä¸ª mystery å‡½æ•°ã€‚\n",
    "\n",
    "LlamaIndex ä¸­çš„æ ¸å¿ƒæŠ½è±¡æ˜¯å‡½æ•°å·¥å…·ï¼ˆ**FunctionTool**ï¼‰ã€‚**æ­¤å‡½æ•°å·¥å…·ä¼šåŒ…è£…æ‚¨æä¾›ç»™å®ƒçš„ä»»ä½•å…·ä½“çš„ Python å‡½æ•°**ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬çœ‹åˆ°å‡½æ•°å·¥å…·æ¥å—äº†è¿™é‡Œå®šä¹‰çš„ add å‡½æ•°ä»¥åŠä¸€ä¸ª mystery å‡½æ•°ï¼ˆä¹Ÿå°±æ˜¯ x + y ä¹˜ä»¥ x + yï¼‰ã€‚æ‚¨å¯ä»¥çœ‹åˆ° add å’Œ mystery éƒ½æœ‰ x å’Œ y å˜é‡çš„**ç±»å‹æ³¨é‡Š**ï¼Œè¿˜æœ‰æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆ**docstring**ï¼‰ã€‚è¿™ä¸ä»…ä»…æ˜¯ä¸ºäº†ç¼–ç¨‹è§„èŒƒç›®çš„ï¼Œè¿™å®é™…ä¸Šå¾ˆé‡è¦ï¼Œå› ä¸ºè¿™äº›ä¸œè¥¿å°†è¢«ç”¨ä½œ LLM çš„**æç¤ºï¼ˆPromptsï¼‰**ã€‚ç›®å‰ï¼ŒLlamaIndex çš„å‡½æ•°å·¥å…·å·²ç»ä¸è®¸å¤š LLM æä¾›å•†ï¼ˆåŒ…æ‹¬ OpenAIï¼‰çš„**å‡½æ•°è°ƒç”¨åŠŸèƒ½**è¿›è¡Œäº†åŸç”Ÿé›†æˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a85c750-2568-4c97-a055-f49caf3ee354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int: \n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2092d7-4d01-4c18-9306-2c77a188e9b9",
   "metadata": {},
   "source": [
    "è¦å°†å·¥å…·ä¼ é€’ç»™ LLMï¼Œæ‚¨å¿…é¡»å¯¼å…¥ LLM æ¨¡å—ï¼Œç„¶åè°ƒç”¨ **predict_and_call**ã€‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ˜¾å¼å¯¼å…¥äº† OpenAI æ¨¡å—ï¼Œæ‚¨ä¼šçœ‹åˆ°æ¨¡å‹æ˜¯ **gpt-3.5-turbo**ï¼Œç„¶åæˆ‘ä»¬åœ¨ LLM ä¹‹ä¸Šè°ƒç”¨ predict_and_call å‡½æ•°ã€‚predict_and_call å‡½æ•°çš„ä½œç”¨æ˜¯æ¥å—ä¸€ç»„å·¥å…·ä»¥åŠ**è¾“å…¥æç¤ºå­—ç¬¦ä¸²æˆ–ä¸€ç³»åˆ—èŠå¤©æ¶ˆæ¯**ï¼Œç„¶åå®ƒæ—¢èƒ½å¤Ÿå†³å®šè¦è°ƒç”¨çš„å·¥å…·ï¼Œä¹Ÿèƒ½å¤Ÿè°ƒç”¨å·¥å…·æœ¬èº«ï¼Œå¹¶è¿”å›æœ€ç»ˆçš„å“åº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a521508-7900-465f-9695-471dfd08893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "========================\n",
      "121 <class 'llama_index.core.chat_engine.types.AgentChatResponse'>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool], \n",
    "    \"Tell me the output of the mystery function on 2 and 9\", \n",
    "    verbose=True\n",
    ")\n",
    "print(\"=\" * 24)\n",
    "print(str(response), type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3526ad69-7f82-4c18-aedb-f69f873ac12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "========================\n",
      "121 <class 'llama_index.core.chat_engine.types.AgentChatResponse'>\n"
     ]
    }
   ],
   "source": [
    "# ä¸­æ–‡\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"å°†ä¸¤ä¸ªæ•´æ•°ç›¸åŠ ã€‚\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int: \n",
    "    \"\"\"åœ¨ä¸¤ä¸ªæ•°å­—ä¹‹ä¸Šè¿è¡Œçš„ç¥ç§˜å‡½æ•°ã€‚\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool], \n",
    "    \"å‘Šè¯‰æˆ‘ mystery å‡½æ•°å¯¹ 2 ä¸ 9 è¾“å‡ºçš„ç»“æœ\",\n",
    "    verbose=True\n",
    ")\n",
    "print(\"=\" * 24)\n",
    "print(str(response), type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e5c49-8784-4882-8011-3cf4c583e420",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°äº†è°ƒç”¨å‡½æ•° mystery çš„ä¸­é—´æ­¥éª¤ã€‚å‡½æ•°ä¼ å…¥å‚æ•°ï¼šx ç­‰äº 2ï¼Œy ç­‰äº 9ã€‚æ‰€ä»¥æˆ‘ä»¬çœ‹åˆ°ï¼Œä»£ç å®ç°è°ƒç”¨äº†æ­£ç¡®çš„å·¥å…·ï¼Œä¹Ÿæ¨æ–­å‡ºäº†æ­£ç¡®çš„å‚æ•°ï¼Œè¾“å‡ºæ˜¯ 121ï¼Œ11 ä¹˜ä»¥ 11 æ˜¯ 121ï¼Œæ‰€ä»¥æˆ‘ä»¬å¾—åˆ°äº†æ­£ç¡®çš„ç­”æ¡ˆã€‚ä½†è¯·æ³¨æ„ï¼Œè¿™ä¸ªç®€å•çš„ç¤ºä¾‹å®é™…ä¸Šæ˜¯è·¯ç”±ï¼ˆrouterï¼‰çš„æ‰©å±•ç‰ˆæœ¬ã€‚**LLM ä¸ä»…é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œè¿˜è¦å†³å®šç»™å·¥å…·ç»™äºˆä»€ä¹ˆå‚æ•°**ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ 2.2 å®šä¹‰è‡ªåŠ¨æ£€ç´¢å·¥å…·å°èŠ‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªå…³é”®æ¦‚å¿µåœ¨å‘é‡æœç´¢ä¹‹ä¸Šå®šä¹‰ä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„æ™ºèƒ½ä½“å±‚ã€‚**LLM ä¸ä»…å¯ä»¥é€‰æ‹©å‘é‡æœç´¢ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®©å®ƒæ¨æ–­å…ƒæ•°æ®è¿‡æ»¤å™¨**ï¼Œè¿™æ˜¯ä¸€ä¸ªç»“æ„åŒ–çš„æ ‡ç­¾åˆ—è¡¨ï¼Œæœ‰åŠ©äºè¿”å›ä¸€ç»„æ›´ç²¾ç¡®çš„æœç´¢ç»“æœã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸å‰é¢ç›¸åŒçš„è®ºæ–‡ MetaGPTï¼Œè¿™æ¬¡è®©æˆ‘ä»¬å…³æ³¨èŠ‚ç‚¹æœ¬èº«ï¼Œæˆ–è€…å—ï¼Œå› ä¸ºæˆ‘ä»¬å°†æŸ¥çœ‹é™„åŠ åˆ°è¿™äº›å—çš„å®é™…å…ƒæ•°æ®ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e948754-315e-4e54-9a12-1b054d6678db",
   "metadata": {},
   "source": [
    "### 2.2 å®šä¹‰è‡ªåŠ¨æ£€ç´¢å·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31316db-e97a-4743-8ee3-fa848c138c09",
   "metadata": {},
   "source": [
    "åŠ è½½æ•°æ®ã€‚ä¸‹è½½è¿è¡Œä»£ç æ‰€éœ€çš„ **MetaGPT è®ºæ–‡** PDFï¼š\n",
    "\n",
    "- ç›´æ¥è®¿é—®è®ºæ–‡é“¾æ¥å¹¶ä¸‹è½½ï¼šhttps://openreview.net/forum?id=VtmBAGCN7o ï¼Œç„¶åå°† PDF æ–‡ä»¶æ”¾ç½®åœ¨ä»£ç ç›®å½•ä¸‹ã€‚\n",
    "\n",
    "- æˆ–è€…åœ¨ jupyter notebook ä¸­ç›´æ¥è¿è¡Œï¼š!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c80324-fedc-49f6-a82e-f7de73022a1d",
   "metadata": {},
   "source": [
    "ä¸‹é¢è¿™è¡Œä»£ç çš„åŠŸèƒ½æ˜¯ä»ç»™å®šçš„ URL ä¸‹è½½ä¸€ä¸ª PDF æ–‡æ¡£ï¼Œå¹¶å°†å…¶ä»¥ \"metagpt.pdf\" ä¸ºåä¿å­˜åˆ°å½“å‰å·¥ä½œç›®å½•ä¸‹ã€‚\n",
    "\n",
    "- `!`ï¼šè¿™ä¸ªç¬¦å·é€šå¸¸åœ¨ Jupyter Notebook ç¯å¢ƒä¸­ç”¨æ¥æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ã€‚\n",
    "\n",
    "- `wget`ï¼šè¿™æ˜¯å®é™…æ‰§è¡Œä¸‹è½½æ“ä½œçš„å‘½ä»¤è¡Œå·¥å…·ã€‚\n",
    "\n",
    "- `\"https://openreview.net/pdf?id=VtmBAGCN7o\"`ï¼šè¿™æ˜¯ä½ æƒ³è¦ä¸‹è½½çš„è®ºæ–‡ PDF çš„ URLã€‚\n",
    "\n",
    "- `-O metagpt.pdf`ï¼šè¿™ä¸ªé€‰é¡¹æŒ‡å®šäº†ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°ä¿å­˜åç§°ã€‚`-O`ï¼ˆå¤§å†™å­—æ¯ Oï¼‰åé¢è·Ÿç€çš„ `metagpt.pdf` æ˜¯ä½ å¸Œæœ›ä¿å­˜ä¸‹è½½æ–‡ä»¶æ—¶ä½¿ç”¨çš„åç§°ã€‚å¦‚æœä¸ä½¿ç”¨ `-O` é€‰é¡¹ï¼Œ`wget` ä¼šä½¿ç”¨ URL ä¸­æœ€åä¸€éƒ¨åˆ†ä½œä¸ºæ–‡ä»¶åæ¥ä¿å­˜ä¸‹è½½å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b09ebfe-b78c-457c-bba7-698f55e6eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-01 21:55:24--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16911937 (16M) [application/pdf]\n",
      "Saving to: â€˜metagpt.pdfâ€™\n",
      "\n",
      "metagpt.pdf         100%[===================>]  16.13M  34.9KB/s    in 6m 52s  \n",
      "\n",
      "2024-06-01 22:02:17 (40.1 KB/s) - â€˜metagpt.pdfâ€™ saved [16911937/16911937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8e2c44-0335-4d49-a2d8-8c113a5a7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# åŠ è½½æ–‡ä»¶ã€‚ä½¿ç”¨ LlamaIndex ä¸­çš„ç®€å•ç›®å½•é˜…è¯»å™¨æ¥åŠ è½½æ­¤ pdf æ–‡ä»¶çš„è§£æè¡¨ç¤ºã€‚\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847055d0-5590-4b05-82ce-8df040e74c34",
   "metadata": {},
   "source": [
    "è¿™é‡Œçš„æ¯ä¸ªèŠ‚ç‚¹éƒ½ä»£è¡¨ä¸€ä¸ªå—ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸€ä¸ªç¤ºä¾‹å—çš„å†…å®¹ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹ç¬¬ä¸€ä¸ªå—çš„å†…å®¹ï¼Œé€šè¿‡æ‰§è¡Œ node.getContent æ¥å®Œæˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a91323b-8fe4-4e07-b9ae-177edf6c409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# ä½¿ç”¨å¥å­åˆ†å‰²å™¨å°†è¿™äº›æ–‡æ¡£åˆ†å‰²æˆä¸€ç»„å¶æ•°å—ï¼Œå—å¤§å°ä¸º 1024ã€‚\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885bb7e-460c-4219-8db2-2b1cec8c11cd",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†å…ƒæ•°æ®æ¨¡å¼è®¾ç½®ä¸º `all`ï¼Œè¿™æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„è®¾ç½®ï¼Œå®é™…ä¸Šä¸ä»…å¯ä»¥æ‰“å°èŠ‚ç‚¹æœ¬èº«çš„å†…å®¹ï¼Œè¿˜å¯ä»¥æ‰“å°é™„åŠ åˆ°æ–‡æ¡£çš„å…ƒæ•°æ®ï¼Œè¿™äº›å…ƒæ•°æ®å°†ä¼ æ’­åˆ°æ¯ä¸ªèŠ‚ç‚¹ã€‚ç»“æœæ‰“å°å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933122bc-74d7-4d43-ac92-5c4cfd3e37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-06-01\n",
      "last_modified_date: 2024-06-01\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1âˆ—, Mingchen Zhuge2âˆ—, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1â€ ,JÂ¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "âˆ—These authors contributed equally to this work.\n",
      "â€ Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d15db-89f5-4193-8b9b-20de80fb730d",
   "metadata": {},
   "source": [
    "åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°ï¼Œä¸€æ—¦æˆ‘ä»¬æ‰“å°å‡ºæ¥ï¼Œæˆ‘ä»¬ä¸ä»…å¾—åˆ°äº†è®ºæ–‡é¦–é¡µçš„è§£æè¡¨ç¤ºï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°**é™„åŠ åœ¨é¡¶éƒ¨çš„å…ƒæ•°æ®**ã€‚æ‰€ä»¥è¿™åŒ…æ‹¬å‡ ä»¶äº‹ã€‚å–å€¼ä¸º 1 çš„é¡µæ ‡ç­¾ï¼›**æ–‡ä»¶åï¼ˆmetagpt.pdfï¼‰ã€æ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶ç±»å‹ã€æ–‡ä»¶å¤§å°ä»¥åŠåˆ›å»ºå’Œç»“æŸæ—¥æœŸ**ã€‚\n",
    "\n",
    "æ­¤å¤–ï¼Œæˆ‘ä»¬è¦ç‰¹åˆ«æ³¨æ„é¡µé¢æ ‡ç­¾ã€‚å› ä¸ºï¼Œä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å®é™…è¿›å…¥å¹¶å°è¯•ä¸åŒçš„èŠ‚ç‚¹ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°æˆ‘ä»¬å®é™…ä¸Šå¾—åˆ°äº†ä¸åŒçš„é¡µç ã€‚æ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šç»™æ¯ä¸ªå—éƒ½æ·»åŠ äº†é¡µç æ³¨é‡Šã€‚æ¥ä¸‹æ¥ï¼Œ**æˆ‘ä»¬å°†åœ¨è¿™äº›èŠ‚ç‚¹ä¸Šå®šä¹‰ä¸€ä¸ªå‘é‡å­˜å‚¨ç´¢å¼•**ã€‚è¿™å°†åŸºæœ¬ä¸Šåœ¨è¿™äº›èŠ‚ç‚¹ä¸Šæ„å»º RAG ç´¢å¼•ç®¡é“ã€‚å®ƒä¼šä¸ºæ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸€ä¸ªåµŒå…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæŸ¥è¯¢å¼•æ“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f73540-4766-4678-8b20-c0ee3bb1680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436546c-7c31-4bed-8cf4-4a0840289183",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å®é™…ä¸Šå¯ä»¥å°è¯•é€šè¿‡å…ƒæ•°æ®è¿‡æ»¤å™¨æŸ¥è¯¢æ­¤ RAG ç®¡é“ï¼Œåªæ˜¯ä¸ºäº†å‘æ‚¨å±•ç¤ºå…ƒæ•°æ®è¿‡æ»¤çš„å·¥ä½œåŸç†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯¼å…¥è¿™ä¸ªåä¸º `MetadataFilters` çš„å¯¹è±¡ï¼Œç„¶åæˆ‘ä»¬åªéœ€æŒ‡å®šä¸€ä¸ªè¿‡æ»¤å™¨ï¼Œå…¶ä¸­é¡µé¢æ ‡ç­¾çš„å€¼è®¾ç½® \"2\"ï¼›å¦å¤–ï¼Œsimilarity_top_k ä¹Ÿç­‰äº 2ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬å°†å…¶å®šä¹‰ä¸ºæŸ¥è¯¢å¼•æ“ï¼Œå¹¶ä¸”æˆ‘ä»¬æŸ¥è¯¢ MetaGPT è®ºæ–‡ä¸­çš„ä¸€äº›é«˜æ°´å¹³ç»“æœã€‚å¦‚æœæˆ‘ä»¬è§‚å¯Ÿä¸€ä¸‹æºèŠ‚ç‚¹ï¼Œä¸€æ—¦æˆ‘ä»¬è¿è¡Œå®ƒï¼Œæˆ‘ä»¬æŸ¥è¯¢åˆ° MetaGPT çš„ä¸€äº›é«˜æ°´å¹³ç»“æœã€‚å½“æˆ‘ä»¬æ”¶åˆ°å“åº”æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆçœ‹ä¸€ä¸‹å“åº”å­—ç¬¦ä¸²ï¼Œå®ƒæ¦‚è¿°äº† MetaGPT çš„æ€»ä½“ç»“æœã€‚ä½†è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹é¡µç ã€‚æˆ‘ä»¬è¿­ä»£æºèŠ‚ç‚¹æ—¶ï¼Œå®é™…ä¸Šå¯ä»¥æ‰“å°å‡º**é™„åŠ åˆ°è¿™äº›æºèŠ‚ç‚¹çš„å…ƒæ•°æ®**ã€‚æˆ‘ä»¬çœ‹åˆ°è¿™é‡Œçš„é¡µé¢æ ‡ç­¾ç­‰äº \"2\"ã€‚å› æ­¤æˆ‘ä»¬è§‚å¯Ÿåˆ°å®ƒèƒ½å¤Ÿæ­£ç¡®è¿‡æ»¤é¡µç ï¼Œ**ä»…å°†æœç´¢é™åˆ¶ä¸ºé¡µé¢æ ‡ç­¾ç­‰äº 2 çš„é¡µé¢**ã€‚è¿™è¯´æ˜æˆ‘ä»¬çš„æŸ¥è¯¢å¼•æ“å¾ˆèªæ˜ï¼Œå®ƒçŸ¥é“æˆ‘ä»¬åªæƒ³çœ‹æ ‡ç­¾ä¸º \"2\" çš„è®ºæ–‡é¡µé¢çš„ä¿¡æ¯ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±ä¸ä¼šè¢«å…¶ä»–ä¸ç›¸å…³çš„é¡µé¢å¹²æ‰°ï¼Œå¯ä»¥æ›´å¿«åœ°æ‰¾åˆ°æˆ‘ä»¬æƒ³è¦çš„ç­”æ¡ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3bbefb1-9d59-44c6-a505-5e8ab8e4f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are some high-level results of MetaGPT?\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830e928c-d2ee-42b7-92ca-cac5f72e0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some high-level results of MetaGPT include achieving a new state-of-the-art in code generation benchmarks with 85.9% and 87.7% in Pass@1, outperforming other popular frameworks like AutoGPT, LangChain, AgentVerse, and ChatDev. Additionally, MetaGPT excels in handling higher levels of software complexity and providing extensive functionality, as evidenced by achieving a 100% task completion rate in experimental evaluations.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350dbfe4-9255-4016-8d0a-eac1fdb2cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c825b2cf-a788-4d9d-8a52-45c4f526b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸­æ–‡\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"MetaGPT å–å¾—äº†å“ªäº›é«˜æ°´å¹³çš„ç»“æœï¼Ÿ\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d214011c-9f3c-40f7-8b10-7c670782f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaGPTåœ¨ä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†85.9%å’Œ87.7%çš„ä¸€çº§é€šè¿‡ç‡ï¼Œè¶…è¶Šäº†å…¶ä»–æµè¡Œçš„æ¡†æ¶ï¼Œå¦‚AutoGPTï¼ŒLangChainï¼ŒAgentVerseå’ŒChatDevã€‚æ­¤å¤–ï¼Œåœ¨å¤„ç†æ›´é«˜çº§åˆ«çš„è½¯ä»¶å¤æ‚æ€§å’Œæä¾›å¹¿æ³›åŠŸèƒ½æ–¹é¢ï¼ŒMetaGPTä¹Ÿè¡¨ç°å‡ºè‰²ã€‚\n",
      "----------------------------------------------------------------------------------------\n",
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "print(str(response))\n",
    "print(\"-\" * 88)\n",
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306807f6-c383-4d2b-91ac-1cb989cc7578",
   "metadata": {},
   "source": [
    "æœ¬æ•™ç¨‹çš„æœ€åä¸€èŠ‚å°†è¿™ä¸ªæ•´ä½“æ£€ç´¢å·¥å…·åŒ…è£…æˆä¸€ä¸ªå‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°æ¥å—æŸ¥è¯¢å­—ç¬¦ä¸²å’Œé¡µç ä½œä¸ºè¿‡æ»¤å™¨ã€‚**LLM å®é™…ä¸Šå¯ä»¥æ¨æ–­è¦è¿‡æ»¤ç”¨æˆ·æŸ¥è¯¢çš„é¡µç **ï¼Œè€Œä¸æ˜¯è®©ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šå…ƒæ•°æ®è¿‡æ»¤å™¨ã€‚\n",
    "\n",
    "è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå…ƒæ•°æ®å…¶å®ä¸ä»…é™äºé¡µç ã€‚**æ‚¨å¯ä»¥é€šè¿‡ LlamaIndex æŠ½è±¡å®šä¹‰ä»»ä½•æƒ³è¦çš„å…ƒæ•°æ®**ï¼Œå¦‚èŠ‚ IDsã€é¡µçœ‰ã€é¡µè„šæˆ–å…¶ä»–ä»»ä½•å†…å®¹ã€‚ä½¿ç”¨è®¸å¤šå…ƒæ•°æ®è¿‡æ»¤å™¨çš„èƒ½åŠ›åœ¨ GPT-4 ç­‰æ›´å¥½çš„å¤§è¯­è¨€æ¨¡å‹ä¸­å°¤ä¸ºçªå‡ºï¼Œå› æ­¤æˆ‘ä»¬å¼ºçƒˆå»ºè®®è¯»è€…è‡ªè¡Œå®è·µä¸€ä¸‹ã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªå°è£…å®ƒçš„ Python å‡½æ•°ã€‚æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåä¸º **vector_query** çš„å‡½æ•°ï¼Œå®ƒæ¥å—æŸ¥è¯¢å’Œé¡µç ã€‚è¿™å…è®¸æ‚¨å¯¹ç´¢å¼•æ‰§è¡Œå‘é‡æœç´¢ï¼Œå¹¶æŒ‡å®šé¡µç ä½œä¸ºå…ƒæ•°æ®è¿‡æ»¤å™¨ã€‚æœ€åï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå‘é‡æŸ¥è¯¢ FunctionTool.from_defaultsã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°† vector_query å‡½æ•°ä¼ é€’åˆ°å‘é‡æŸ¥è¯¢å·¥å…·ä¸­ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥å°†å…¶ä¸è¯­è¨€æ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œè®©æˆ‘ä»¬å€ŸåŠ© gpt-3.5-turbo è°ƒç”¨æ­¤å·¥å…·ã€‚æˆ‘ä»¬ä¼šå‘ç° LLM èƒ½å¤Ÿæ¨æ–­å­—ç¬¦ä¸²ä»¥åŠå…ƒæ•°æ®è¿‡æ»¤å™¨ã€‚æˆ‘ä»¬åœ¨å‘é‡æŸ¥è¯¢å·¥å…·ä¸Šè¿›è¡Œäº† predict_and_callï¼Œå¹¶æç¤ºäº†åŒæ ·çš„é—®é¢˜ï¼šå¦‚ç¬¬äºŒé¡µæ‰€è¿°çš„ MetaGPT çš„é«˜æ°´å¹³ç»“æœã€‚åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ° LLM èƒ½å¤Ÿåˆ¶å®šæ­£ç¡®çš„æŸ¥è¯¢ï¼ˆMetaGPT çš„é«˜æ°´å¹³ç»“æœï¼‰ï¼Œä»¥åŠæŒ‡å®šé¡µç ï¼ˆå–å€¼ä¸º \"2\"ï¼‰ã€‚ç»“æœæ˜¯æˆ‘ä»¬å¾—åˆ°äº†æ­£ç¡®çš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63594a7-46ff-47b9-8f68-517e6a502ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "def vector_query(query: str, page_number: int) -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "\n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (int): Filter by set of pages. Leave BLANK if we want to perform a vector search over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "    \"\"\"\n",
    "    print(page_number, type(page_number))\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": str(page_number)}]\n",
    "    print(metadata_dicts)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19a31a3-22c3-4fca-ac32-ff3e3d91cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 2, \"query\": \"high-level results of MetaGPT\"}\n",
      "2 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '2'}]\n",
      "=== Function Output ===\n",
      "MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It stands out in handling higher levels of software complexity and offering extensive functionality. In experimental evaluations, MetaGPT achieves a 100% task completion rate, demonstrating robustness and efficiency in terms of time and token costs.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc3418a-021b-4eaa-b1d6-57e0b279a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 2, \"query\": \"MetaGPT \\u7684\\u9ad8\\u6c34\\u5e73\\u7ed3\\u679c\"}\n",
      "2 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '2'}]\n",
      "=== Function Output ===\n",
      "MetaGPT åœ¨ä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ–°çš„æŠ€æœ¯æ°´å¹³ï¼ŒPass@1 åˆ†åˆ«ä¸º 85.9% å’Œ 87.7%ï¼Œåœ¨å¤„ç†æ›´é«˜çº§åˆ«çš„è½¯ä»¶å¤æ‚æ€§å’Œæä¾›å¹¿æ³›åŠŸèƒ½æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚åœ¨å®éªŒè¯„ä¼°ä¸­ï¼ŒMetaGPT å®ç°äº† 100% çš„ä»»åŠ¡å®Œæˆç‡ï¼Œå±•ç¤ºäº†è®¾è®¡çš„ç¨³å¥æ€§å’Œæ•ˆç‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ä¸­æ–‡\n",
    "def vector_query(query: str, page_number: int) -> str:\n",
    "    \"\"\"å¯¹ç´¢å¼•è¿›è¡Œå‘é‡æœç´¢ã€‚\n",
    "\n",
    "    query (str)ï¼šè¦è¿›è¡ŒåµŒå…¥çš„å­—ç¬¦ä¸²æŸ¥è¯¢ã€‚\n",
    "    page_numbers (int)ï¼šæŒ‰é¡µé¢é›†è¿‡æ»¤ã€‚å¦‚æœè¦åœ¨æ‰€æœ‰é¡µé¢ä¸Šè¿›è¡Œå‘é‡æœç´¢ï¼Œåˆ™ç•™ç©ºã€‚å¦åˆ™ï¼ŒæŒ‰æŒ‡å®šçš„é¡µé¢é›†è¿‡æ»¤ã€‚\n",
    "\n",
    "    \"\"\"\n",
    "    print(page_number, type(page_number))\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": str(page_number)}]\n",
    "    print(metadata_dicts)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    \"ç¬¬ 2 é¡µä¸­æè¿°çš„ MetaGPT çš„é«˜æ°´å¹³ç»“æœæ˜¯ä»€ä¹ˆï¼Ÿè¯·ç”¨ä¸­æ–‡å›ç­”ã€‚\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f2e18-fc7a-476f-a344-4c4e0aea86bb",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥å¿«é€ŸéªŒè¯æºèŠ‚ç‚¹ï¼Œå¯ä»¥çœ‹åˆ°æºèŠ‚ç‚¹çš„é¡µé¢æ ‡ç­¾ï¼Œæœ‰ä¸€ä¸ªè¿”å›çš„æºèŠ‚ç‚¹ï¼Œå®ƒçš„é¡µé¢æ ‡ç­¾æ˜¯ \"2\"ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c538c019-089e-45fb-93a2-d419e3a1bfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2984818-d4fe-4f5a-8094-461a00b32b39",
   "metadata": {},
   "source": [
    "### 2.3 ç»¼åˆçš„å·¥å…·é€‰æ‹©ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd826632-9b6b-48bf-b49b-82a60e77a0c3",
   "metadata": {},
   "source": [
    "æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä» 2. è·¯ç”±æŸ¥è¯¢å¼•æ“ Router Query Engine æ•™ç¨‹ä¸­çš„ router ç¤ºä¾‹ä¸­å¼•å…¥æ‘˜è¦å·¥å…·ï¼Œå¹¶å°†å…¶ä¸å‘é‡æ£€ç´¢å·¥å…·æœ‰æœºç»“åˆèµ·æ¥ï¼Œåˆ›å»ºè¿™ä¸ªç»¼åˆçš„å·¥å…·é€‰æ‹©ç³»ç»Ÿã€‚æ‰€ä»¥ï¼Œä¸‹é¢è¿™æ®µä»£ç åªæ˜¯åœ¨ç›¸åŒçš„èŠ‚ç‚¹é›†ä¸Šè®¾ç½®äº†ä¸€ä¸ªæ‘˜è¦ç´¢å¼•ï¼Œå¹¶ç”¨ä¸€ä¸ªç±»ä¼¼äº 2. è·¯ç”±æŸ¥è¯¢å¼•æ“ Router Query Engine æ•™ç¨‹ä¸­çš„æ‘˜è¦å·¥å…·å°†å…¶åŒ…è£…èµ·æ¥ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18186ba-9cf2-486a-ab24-3777ef0e6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4719ad-66fb-4558-a68a-121cfe774e13",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å†æ¬¡å°è¯•å·¥å…·è°ƒç”¨ã€‚è¿™æ ·ä¸€æ¥ï¼Œ**LLM è¦åšçš„ä»»åŠ¡ç•¥æœ‰æé«˜éš¾åº¦**ï¼Œå®ƒä¸ä»…è¦å®é™…é€‰æ‹©æ­£ç¡®çš„å·¥å…·ï¼Œè¿˜è¦æ¨æ–­å‡½æ•°å‚æ•°ã€‚æˆ‘ä»¬è¯¢é—®è®ºæ–‡ç¬¬ 8 é¡µä¸Š MetaGPT ä¸ ChatDev çš„æ¯”è¾ƒæƒ…å†µã€‚æˆ‘ä»¬çœ‹åˆ°å®ƒå®é™…ä¸Šè¿˜æ˜¯è°ƒç”¨äº†ä¸€ä¸ªå‘é‡å·¥å…·ï¼Œé¡µç ç­‰äº \"8\"ï¼Œè€Œä¸”å®ƒèƒ½å¤Ÿç»™å‡ºæ­£ç¡®çš„ç­”æ¡ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c6d1d3c-2116-4ea2-99cb-2a3a2975246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 8, \"query\": \"MetaGPT comparisons with ChatDev\"}\n",
      "8 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '8'}]\n",
      "=== Function Output ===\n",
      "MetaGPT outperforms ChatDev on the SoftwareDev dataset in various metrics. For example, MetaGPT achieves a higher score in executability, takes less time for software generation, uses more tokens but requires fewer tokens to generate one line of code compared to ChatDev. Additionally, MetaGPT demonstrates better performance in code statistics and human revision cost when compared to ChatDev.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c573e-f0d1-4569-ad47-fbad879adefb",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡æ‰“å°å‡ºæ¥æºèŠ‚ç‚¹æ¥éªŒè¯è¿™ä¸€ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03154b63-3c04-409a-bbbd-d157db4415a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7716b78f-e4cc-4688-b51b-fa47dd68e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 8, \"query\": \"MetaGPT \\u4e0e ChatDev \\u7684\\u5bf9\\u6bd4\\u5206\\u6790\\u7ed3\\u679c\"}\n",
      "8 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '8'}]\n",
      "=== Function Output ===\n",
      "MetaGPT åœ¨è½¯ä»¶å¼€å‘æ•°æ®é›†ä¸­å‡ ä¹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äº ChatDevã€‚ä¾‹å¦‚ï¼Œåœ¨å¯æ‰§è¡Œæ€§æ–¹é¢ï¼ŒMetaGPT è·å¾—äº†3.75çš„åˆ†æ•°ï¼Œæ¥è¿‘4ï¼ˆå®Œç¾ï¼‰ã€‚æ­¤å¤–ï¼ŒMetaGPT ç”Ÿæˆä¸€è¡Œä»£ç æ‰€éœ€çš„æ—¶é—´æ›´çŸ­ï¼ˆ503ç§’ï¼‰ï¼Œæ˜æ˜¾å°‘äº ChatDevã€‚è€ƒè™‘åˆ°ä»£ç ç»Ÿè®¡å’Œäººå·¥ä¿®è®¢æˆæœ¬ï¼ŒMetaGPT ä¹Ÿæ˜æ˜¾ä¼˜äº ChatDevã€‚è™½ç„¶ MetaGPT éœ€è¦æ›´å¤šçš„æ ‡è®°ï¼ˆ24,613æˆ–31,255æ¯”19,292å¤šï¼‰ï¼Œä½†åªéœ€è¦126.5/124.3ä¸ªæ ‡è®°æ¥ç”Ÿæˆä¸€è¡Œä»£ç ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒChatDev ä½¿ç”¨äº†248.9ä¸ªæ ‡è®°ã€‚è¿™äº›ç»“æœçªæ˜¾äº†åœ¨å¤šä¸ªä»£ç†ä¹‹é—´çš„åä½œä¸­ SOP çš„å¥½å¤„ã€‚\n",
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "# ä¸­æ–‡\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"å¦‚æœæ‚¨æƒ³äº†è§£ MetaGPT çš„æ¦‚è¦ï¼Œè¿™ä¸ªå·¥å…·ä¼šå¾ˆæœ‰ç”¨ã€‚\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"ç¬¬ 8 é¡µæè¿°çš„ MetaGPT ä¸ ChatDev çš„å¯¹æ¯”åˆ†æç»“æœæ˜¯ä»€ä¹ˆï¼Ÿå¿…é¡»ç”¨ä¸­æ–‡å›ç­”ã€‚\", \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dba95-d0c5-432b-9217-515dab13f38d",
   "metadata": {},
   "source": [
    "æœ€åï¼Œæˆ‘ä»¬å¯ä»¥é—®ä¸€ä¸ªé—®é¢˜ï¼Œå³**è¿™ç¯‡è®ºæ–‡çš„æ‘˜è¦æ˜¯ä»€ä¹ˆ**ï¼Œä»¥æ˜¾ç¤º LLM åœ¨å¿…è¦æ—¶ä»ç„¶èƒ½å¤Ÿé€‰æ‹©æ‘˜è¦å·¥å…·ã€‚æˆ‘ä»¬çœ‹åˆ°å®ƒç»™å‡ºäº†æ­£ç¡®çš„å›åº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29c21c9f-9a84-4690-8a0c-8e82c4ef2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"Summary of the MetaGPT paper\"}\n",
      "=== Function Output ===\n",
      "The MetaGPT paper introduces a meta-programming framework that utilizes Standardized Operating Procedures (SOPs) to enhance multi-agent systems based on Large Language Models (LLMs). It focuses on role specialization, structured communication interfaces, and executable feedback mechanisms to improve code generation quality during runtime. The framework involves agents like Product Managers, Architects, Engineers, and QA Engineers, each contributing specialized outputs to efficiently complete software development tasks. Additionally, it introduces the concept of AgentStore for creating and developing agents within the framework. The paper discusses the transformation of abstract requirements into detailed software designs, emphasizing the importance of structured messaging and feedback mechanisms. It addresses challenges such as reducing code hallucinations, utilizing context efficiently, and managing information overload. The system prioritizes user data privacy and security by operating locally, with open-source options available for backends. Ethical considerations like skill obsolescence, transparency, and privacy are also touched upon.\n"
     ]
    }
   ],
   "source": [
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What is a summary of the MetaGPT paper?\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7153e63-5da6-49f2-a144-d684b38963fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"MetaGPT\"}\n",
      "=== Function Output ===\n",
      "MetaGPT is a meta-programming framework that enhances problem-solving capabilities in multi-agent systems based on Large Language Models (LLMs). It incorporates role specialization, structured communication interfaces, and efficient sharing mechanisms to facilitate collaboration among agents. MetaGPT also utilizes an executable feedback mechanism to improve code generation quality during runtime. In experiments, MetaGPT has shown state-of-the-art performance on various benchmarks, outperforming other frameworks in tasks like code generation and software development. Additionally, MetaGPT is a framework that utilizes natural language programming to generate software applications based on provided prompts and requirements. It simplifies the process of transforming abstract requirements into detailed class and function designs through a specialized division of labor and standard operating procedures workflow. MetaGPT has been shown to outperform other models in terms of generating executable code, with a focus on structured messaging and feedback mechanisms to enhance communication and code execution. The framework also addresses challenges such as efficiently using context, reducing hallucinations in code generation, and managing information overload through a global message pool and subscription mechanism. Furthermore, MetaGPT emphasizes transparency, accountability, privacy, and data security, operating locally to ensure user data privacy and security.\n"
     ]
    }
   ],
   "source": [
    "# ä¸­æ–‡\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"å¦‚æœæ‚¨æƒ³äº†è§£ MetaGPT çš„æ¦‚è¦ï¼Œè¿™ä¸ªå·¥å…·ä¼šå¾ˆæœ‰ç”¨ã€‚\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# å‘ç°ä½¿ç”¨ LlamaIndex æ¡†æ¶ï¼Œå³ä½¿æ˜¯ä¸­æ–‡ Promptï¼Œä»å¯èƒ½å‡ºç°ä¸éµå¾ªæŒ‡ä»¤çš„æƒ…å†µã€‚å¤šæ¬¡è°ƒè¯•ï¼Œè¾“å‡ºç»“æœä»æ˜¯è‹±æ–‡ã€‚\n",
    "# å› æ­¤ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥æ¢ä¸€ç¯‡ä¸­æ–‡çš„è®ºæ–‡ PDF æ¥åšå®éªŒï¼\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"ç”¨ä¸­æ–‡è¾“å‡º MetaGPT çš„æ‘˜è¦ã€‚\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a3ed5-1123-401c-9413-bfaf86f26415",
   "metadata": {},
   "source": [
    "## ä¸‰ã€æœ¬ç« å°ç»“\n",
    "***\n",
    "\n",
    "ğŸ§ğŸ’ğŸ¤– äººä¸å¤§å¤šæ•°åŠ¨ç‰©çš„æ ¹æœ¬åŒºåˆ«åœ¨äºäººèƒ½åˆ¶é€ å’Œä½¿ç”¨å·¥å…·ã€‚åŒæ ·åœ°ï¼Œæ™ºèƒ½ä½“ä¹Ÿèƒ½åˆ©ç”¨å„ç§å¤–éƒ¨å·¥å…·æ¥å®ç°åŠŸèƒ½æ‰©å±•å’Œæ•ˆç‡æå‡ã€‚\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ LLM æ¥é€‰æ‹©è¦æ‰§è¡Œçš„å‡½æ•°ï¼Œå¹¶æ¨æ–­è¦ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°ã€‚é€šè¿‡å·¥å…·è°ƒç”¨ï¼ŒLLM ä¸ä»…èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œè¿˜èƒ½å†³å®šè¦ç»™å·¥å…·ä»€ä¹ˆå‚æ•°ã€‚è¿™ä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿæå‡ºæ›´å¤šé—®é¢˜ï¼Œå¹¶é€šè¿‡å·¥å…·è°ƒç”¨è·å¾—æ¯”æ ‡å‡† RAG æŠ€æœ¯æ›´ç²¾ç¡®çš„ç»“æœã€‚\n",
    "\n",
    "æ•™ç¨‹ä¸­è¿˜å±•ç¤ºäº†å¦‚ä½•åœ¨å‘é‡æœç´¢ä¹‹ä¸Šå®šä¹‰ä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„æ™ºèƒ½ä½“å±‚ã€‚LLM å¯ä»¥é€‰æ‹©å‘é‡æœç´¢ï¼Œå¹¶æ¨æ–­å…ƒæ•°æ®è¿‡æ»¤å™¨ï¼Œä»¥è¿”å›æ›´ç²¾ç¡®çš„æœç´¢ç»“æœã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å°†æ•´ä½“æ£€ç´¢å·¥å…·å°è£…æˆä¸€ä¸ªå‡½æ•°ï¼Œä½¿ LLM èƒ½å¤Ÿæ¨æ–­ç”¨æˆ·æŸ¥è¯¢çš„å…ƒæ•°æ®è¿‡æ»¤å™¨ã€‚é€šè¿‡ LLM ç´¢å¼•æŠ½è±¡ï¼Œå¯ä»¥å®šä¹‰å„ç§å…ƒæ•°æ®ï¼Œå¦‚ç« èŠ‚ IDsã€é¡µç ã€é¡µçœ‰ã€é¡µè„šç­‰ã€‚\n",
    "\n",
    "âœ¨ï¸ğŸ‰ğŸš€ é‚£ä¹ˆï¼Œ3. å·¥å…·è°ƒç”¨ Tool Calling å°±åˆ°è¿™é‡Œå•¦~ âœ¨ï¸ğŸ‰ğŸš€ \n",
    "\n",
    "ğŸ¤– ä¸‹ä¸€ç«  4. Building an Agent Reasoning Loopï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•æ„å»ºæ™ºèƒ½ä½“æ¨ç†é—­ç¯ï¼ğŸ¤–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
