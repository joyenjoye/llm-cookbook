{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ff1e37-2662-434f-9388-7e5eec3869f4",
   "metadata": {},
   "source": [
    "<div class=\"toc\">\n",
    " <ul class=\"toc-item\">\n",
    "     <li><span><a href=\"#一、引言\" data-toc-modified-id=\"一、引言\">一、引言</a></span></li>\n",
    "     <li>\n",
    "         <span><a href=\"#二、工具调用代码示例\" data-toc-modified-id=\"二、工具调用代码示例\">二、工具调用代码示例</a></span>\n",
    "         <ul class=\"toc-item\">\n",
    "             <li><span><a href=\"##2.1 从 Python 函数定义工具接口\" data-toc-modified-id=\"2.1 从 Python 函数定义工具接口\">2.1 从 Python 函数定义工具接口</a></span></li>\n",
    "             <li><span><a href=\"##2.2 定义自动检索工具\" data-toc-modified-id=\"2.2 定义自动检索工具\">2.2 定义自动检索工具</a></span></li>\n",
    "             <li><span><a href=\"##2.3 综合的工具选择系统\" data-toc-modified-id=\"2.3 综合的工具选择系统\">2.3 综合的工具选择系统</a></span></li>\n",
    "             </ul>\n",
    "         </li>\n",
    "     <li><span><a href=\"#三、本章小结\" data-toc-modified-id=\"三、本章小结\">三、本章小结</a></span></li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56262ca4-0463-4c31-9f1b-fb80eaaa5f31",
   "metadata": {},
   "source": [
    "## 一、引言\n",
    "***\n",
    "\n",
    "<div style=\"display:none;\">大语言模型 (Large Language Models, LLMs) 的优点之一是能够与外部环境交互并采取行动。为了实现这一目标，LLMs 需要使用有效且可靠的接口，我们称之为<strong>工具调用 (Tool Calling)</strong>。</div>\n",
    "\n",
    "在基础的检索增强生成 (Retrieval-Augmented Generation, RAG) 管道中，大语言模型 (Large Language Models, LLMs)  仅用于生成结果。在第二章我们已经展示了如何以略微更复杂的方式使用 LLMs，即利用它来选择最佳的查询引擎来回答用户的查询。这是<strong>工具调用 (Tool Calling)</strong> 的简化形式。\n",
    "\n",
    "<div style=\"display:none;\">大在这个信息爆炸的时代，我们面临着一个前所未有的挑战：如何从海量数据中快速、准确地检索和处理信息。本教程正是为了应对这一挑战而设计的，它将引导我们进入一个由大语言模型（Large Language Models，LLMs）和工具调用（Tool Calling）技术共同构建的智能信息处理新世界。</div>\n",
    "\n",
    "在本章中，LLMs 将不仅被用于选择最佳的查询引擎，还推断出要传递给函数的参数。这使得 LLMs 能够利用向量数据库，而不仅仅是使用其输出。通过工具调用，用户可以进行更多元化的查询，并且获得比标准RAG技术更精确的结果。\n",
    "\n",
    "<div style=\"display:none;\">在本教程中，我们将探索一种革命性的方法，这种方法不仅能够让 LLMs 生成文本，还能使它们在决策过程中扮演更为关键的角色。想象一下，**一个系统能够理解您的查询，自动选择最合适的工具来处理问题，并准确地推断出需要传递给这些工具的参数**。这不再是科幻小说中的场景，而是我们即将揭开的技术现实。\n",
    "\n",
    "我们将从 RAG 管道的基础原理出发，逐步深入到更高级的工具调用概念。您将学习到如何定义工具接口，并通过 Python 函数的签名自动推断参数，这是 LlamaIndex 索引抽象的核心。我们将通过实际的代码示例，展示如何将这些工具传递给 LLM，并利用 predict_and_call 函数来实现智能决策和执行。\n",
    "\n",
    "教程的重点之一是展示 LLMs 如何与向量数据库交互，通过元数据过滤器来优化搜索结果，从而提供更精确的信息检索。这不仅提高了效率，还极大地增强了用户体验。随着代码示例的深入，我们将构建一个复杂的智能体层，它将展示 LLMs 在选择工具和推断参数方面的高级能力。最终，我们将整合所有这些技术，构建一个完整的工具选择系统，它能够理解复杂的用户查询，并提供精确、有用的答案。结果是用户可以提出更多问题，并**通过工具调用获得比标准 RAG 技术更精确的结果**。\n",
    "\n",
    "本教程不仅适合那些对大语言模型和 LLM-based Agent 感兴趣的学生和专业人士，也适合任何希望在信息检索和处理领域保持领先地位的人。让我们一起开启这段激动人心的学习之旅，探索如何利用 LLMs 和工具调用技术，构建下一代 Agentic RAG 系统。那么，让我们开始编码吧~ </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9377328-492c-4bfe-91e0-d550674ce7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 你需要在文件目录下创建一个.env的文件，文件中存放你的 OPENAI_API_KEY=“your OPENAI API Key”\n",
    "# 从 .env 文件将 OPENAI_API_KEY 加载为环境变量。\n",
    "# 当后续使用到 OPENAI 模型时，环境变量会直接被使用于认证(Authentication)。\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "010fec00-f9a2-4c76-aa92-4af16e62998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a4b4e-d852-42ba-a2fa-cfd08de2f205",
   "metadata": {},
   "source": [
    "<br>\n",
    "LlamaIndex 为了实现高效加载和处理数据，有些功能使用了asyncio实现异步编程优化 I/O 操作。然而，asyncio 的设计本身不支持事件循环的嵌套使用，这意味着在已经运行事件循环的环境中，尝试再次启动事件循环或同步运行任务会导致异常，通常会抛出 \"RuntimeError: This event loop is already running\" 错误。 在Jupyter Notebook这样的交互式环境中，因为每个代码单元格（cell）都可能尝试创建或操作事件循环。从而出现事件循环的嵌套使用。\n",
    "\n",
    "为了解决这个问题，nest_asyncio 模块对 asyncio 进行了补丁，允许嵌套使用 asyncio 的函数，例如 asyncio.run() 和 loop.run_until_complete()。这种补丁修改了 asyncio 的行为，临时允许 asyncio 在已有事件循环的环境中正常工作，确保在 Jupyter Notebook 环境中，即使存在已运行的事件循环，也能够正确执行异步任务。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2ba3f-1a6b-47e5-a009-e5390bd3065e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 二、 简单的工具调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7a91f-4064-4bce-8d2e-3ce1ecaca99d",
   "metadata": {},
   "source": [
    "工具调用分为以下几个步骤：\n",
    "- 构建Python函数 (Python function)\n",
    "- 为给定的函数定义工具接口（Tool Interface）\n",
    "- LLM 使用 LlamaIndex 抽象（LlamaIndex abstractions）根据函数的签名（Signature）来推断参数\n",
    "\n",
    "让我们来看一个简单的工具调用例子，了解工具调用的工作原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6dbe4-c423-4684-97dc-aa8acffa3e8e",
   "metadata": {},
   "source": [
    "### 2.1、定义Python函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cbced-09d8-49c3-9d4e-29d746222162",
   "metadata": {},
   "source": [
    "首先，我们定义一个 add 函数和一个 mystery 函数。 值得注意的是，在定义函数时，我们提供了文档字符串、参数列表及其类型用于描述函数的输入输出。这些信息加上函数名本身为函数签名（Signature）。这不仅仅是为了编程规范目的，它后续会被用于生成 LLM 的提示（Prompts）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a85c750-2568-4c97-a055-f49caf3ee354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10113fb-8899-446b-a05a-95e36646c5d1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c4ff2-1d70-4c17-bf85-4520d41e47d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2、定义工具接口"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56843f-c0b8-4d6b-90f4-8967a7d5d298",
   "metadata": {},
   "source": [
    "LlamaIndex 中的核心抽象是函数工具（**FunctionTool**）。**此函数工具会包装您提供给它的任何具体的 Python 函数**，所以，我们看到函数工具接受了这里定义的 add 函数以及一个 mystery 函数（也就是 x + y 乘以 x + y）。您可以看到 add 和 mystery 都有 x 和 y 变量的**类型注释**，还有文档字符串（**docstring**）。这不仅仅是为了编程规范目的，这实际上很重要，因为这些东西将被用作 **LLM 的提示（Prompts）**。目前，LlamaIndex 的函数工具已经与许多 LLM 提供商（包括 OpenAI）的**函数调用功能**进行了原生集成。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a48941f6-a456-4150-82ea-9f464717015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85babd7a-2042-496e-ac9b-1141ceb07e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6c/tn_x_scj0klffm7j_pj2mf7c0000gn/T/ipykernel_73012/307452021.py:1: DeprecationWarning: Call to deprecated method to_openai_function. (Deprecated in favor of `to_openai_tool`, which should be used instead.)\n",
      "  add_tool.metadata.to_openai_function()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'add',\n",
       " 'description': 'add(x: int, y: int) -> int\\nAdds two integers together.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'x': {'title': 'X', 'type': 'integer'},\n",
       "   'y': {'title': 'Y', 'type': 'integer'}},\n",
       "  'required': ['x', 'y']}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_tool.metadata.to_openai_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8ed856e-3667-4419-ad67-3d25bb4708a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# print(inspect.getsource(FunctionTool))\n",
    "# from inspect import signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f1aad-92a5-4166-b178-4593e8eee284",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2、使用 LLMs 进行工具调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2092d7-4d01-4c18-9306-2c77a188e9b9",
   "metadata": {},
   "source": [
    "\n",
    "接下来，我们要将定义好的工具`add_tool` 和 `mystery_tool` 传递给大语言模型（LLM）。首先，加载大语言模型，这里选择的模型为**gpt-3.5-turbo**。 然后我们调用 `predict_and_call` 函数。该函数的输入为：\n",
    "\n",
    "- 工具列表(tools)： 一组工具\n",
    "- 用户查询输入(user_msg)： 输入提示字符串或一系列聊天消息\n",
    "\n",
    "然后它既能够决定要调用的工具，也能够调用工具本身，并返回最终的响应。\n",
    "\n",
    "初始化大语言模型，这里悬着"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a521508-7900-465f-9695-471dfd08893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# 加载大语言模型\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 调用 predict_and_call 函数\n",
    "response = llm.predict_and_call(\n",
    "    tools=[add_tool, mystery_tool],\n",
    "    user_msg=\"Tell me the output of the mystery function on 2 and 9\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b49abb8-315d-4eb8-aa73-4f934df520e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='121', sources=[ToolOutput(content='121', tool_name='mystery', raw_input={'args': (), 'kwargs': {'x': 2, 'y': 9}}, raw_output=121, is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e5c49-8784-4882-8011-3cf4c583e420",
   "metadata": {},
   "source": [
    "这里我们看到了调用函数 mystery 的中间步骤。函数传入参数：x 等于 2，y 等于 9。所以我们看到，代码实现调用了正确的工具，也推断出了正确的参数，输出是 121，11 乘以 11 是 121，所以我们得到了正确的答案。但请注意，这个简单的示例实际上是路由（router）的扩展版本。**LLM 不仅选择合适的工具，还要决定给工具给予什么参数**。\n",
    "\n",
    "下面的 2.2 定义自动检索工具小节，让我们使用这个关键概念在向量搜索之上定义一个稍微复杂一点的智能体层。**LLM 不仅可以选择向量搜索，我们还可以让它推断元数据过滤器**，这是一个结构化的标签列表，有助于返回一组更精确的搜索结果。我们将使用与前面相同的论文 MetaGPT，这次让我们关注节点本身，或者块，因为我们将查看附加到这些块的实际元数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209a750-1d72-4844-8d13-8fcbaff3afd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3、中文示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3526ad69-7f82-4c18-aedb-f69f873ac12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "========================\n",
      "121 <class 'llama_index.core.chat_engine.types.AgentChatResponse'>\n"
     ]
    }
   ],
   "source": [
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"将两个整数相加。\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"在两个数字之上运行的神秘函数。\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    tools=[add_tool, mystery_tool], \n",
    "    user_msg=\"告诉我 mystery 函数对 2 与 9 输出的结果\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e948754-315e-4e54-9a12-1b054d6678db",
   "metadata": {},
   "source": [
    "## 三、 定义自动检索工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31316db-e97a-4743-8ee3-fa848c138c09",
   "metadata": {},
   "source": [
    "这里需要用到的文档为`metagpt.pdf`。已经在当前目录下面。 或者你也可以通过下面的指令来下载文件。\n",
    "\n",
    "```bash\n",
    "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "```\n",
    "\n",
    "`wget` 为linux系统下的下载指令。如果你的系统为Windows或者Mac, 则可以通过curl来下载。\n",
    "\n",
    "```bash\n",
    "!curl -s -o metagpt.pdf \"https://openreview.net/pdf?id=VtmBAGCN7o\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20454a4-fa36-4c5a-9f4b-97fb4f3adf7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.1、加载数据为文档格式\n",
    "\n",
    "使用 LlamaIndex 中的简单目录阅读器来加载此 pdf 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8e2c44-0335-4d49-a2d8-8c113a5a7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"data/metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801dc98-2eb4-4b2c-889d-b2a7fa1de295",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.2、切割文档为节点格式\n",
    "\n",
    "使用句子分割器将这些文档分割成一组节点，每个节点的Token个数少于1024个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a91323b-8fe4-4e07-b9ae-177edf6c409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847055d0-5590-4b05-82ce-8df040e74c34",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "这里的每个节点都代表一个块(chunk)，我们可以通过执行 `node.getContent` 来看看节点的内容。同时可以将元数据模式(metadata_mode)设置为 `all`，不仅可以打印节点本身的文本内容，还可以打印附加到文档的元数据。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d65ab34-359b-4689-81e4-c9f4212084c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: data/metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-06-15\n",
      "last_modified_date: 2024-06-08\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d15db-89f5-4193-8b9b-20de80fb730d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "上面是第一个节点的打印结果。我们不仅得到了论文文本，顶部还包含了文本的元数据(Meta Data)：\n",
    "\n",
    "- 页标签（page_label）: 1\n",
    "- 文件名（file_name）: metagpt.pdf\n",
    "- 文件路径（file_path）: data/metagpt.pdf\n",
    "- 文件类型（file_type）: application/pdf\n",
    "- 文件大小（file_size）: 16911937\n",
    "- 创建日期（creation_date）: 2024-06-15\n",
    "- 上次修改日期（last_modified_date）: 2024-06-08\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b8f7b-5c5d-4f8f-a073-9ba9f784b5b2",
   "metadata": {},
   "source": [
    "### 3.3、定义向量存储索引\n",
    "\n",
    "接下来，我们将在这些节点上定义一个**向量存储索引**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15f73540-4766-4678-8b20-c0ee3bb1680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# 向量存储索引\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887dd18-36af-4a2b-906b-e8ccad49d9b7",
   "metadata": {},
   "source": [
    "### 3.4、创建查询引擎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ccac3fc-c82b-4003-9703-efd705f5a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于向量索引vector_index构建向量查询引擎\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec74446-d4e2-44b5-9fe8-fcca4857c195",
   "metadata": {},
   "source": [
    "这船"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436546c-7c31-4bed-8cf4-4a0840289183",
   "metadata": {},
   "source": [
    "我们实际上可以尝试通过元数据过滤器查询此 RAG 管道，只是为了向您展示元数据过滤的工作原理。因此，我们导入这个名为 `MetadataFilters` 的对象，然后我们只需指定一个过滤器，其中页面标签的值设置 \"2\"；另外，similarity_top_k 也等于 2。\n",
    "\n",
    "因此，我们将其定义为查询引擎，并且我们查询 MetaGPT 论文中的一些高水平结果。如果我们观察一下源节点，一旦我们运行它，我们查询到 MetaGPT 的一些高水平结果。当我们收到响应时，我们首先看一下响应字符串，它概述了 MetaGPT 的总体结果。但至关重要的是，我们将查看页码。我们迭代源节点时，实际上可以打印出**附加到这些源节点的元数据**。我们看到这里的页面标签等于 \"2\"。因此我们观察到它能够正确过滤页码，**仅将搜索限制为页面标签等于 2 的页面**。这说明我们的查询引擎很聪明，它知道我们只想看标签为 \"2\" 的论文页面的信息。这样，我们就不会被其他不相关的页面干扰，可以更快地找到我们想要的答案。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3bbefb1-9d59-44c6-a505-5e8ab8e4f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts([{\"key\": \"page_label\", \"value\": \"2\"}]),  # 根据页码过滤\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66d925-2244-45c8-b040-fa12e1d08ef0",
   "metadata": {},
   "source": [
    "### 3.5、进行查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830e928c-d2ee-42b7-92ca-cac5f72e0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some high-level results of MetaGPT include achieving a new state-of-the-art in code generation benchmarks with 85.9% and 87.7% in Pass@1, outperforming other popular frameworks like AutoGPT, LangChain, AgentVerse, and ChatDev. Additionally, MetaGPT excels in handling higher levels of software complexity and providing extensive functionality, as evidenced by achieving a 100% task completion rate in experimental evaluations.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are some high-level results of MetaGPT?\",)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350dbfe4-9255-4016-8d0a-eac1fdb2cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c825b2cf-a788-4d9d-8a52-45c4f526b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query( \"MetaGPT 取得了哪些高水平的结果？\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d214011c-9f3c-40f7-8b10-7c670782f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaGPT在代码生成基准测试中取得了85.9%和87.7%的一级通过率，超越了其他流行的框架，如AutoGPT，LangChain，AgentVerse和ChatDev。此外，在处理更高级别的软件复杂性和提供广泛功能方面，MetaGPT也表现出色。\n",
      "----------------------------------------------------------------------------------------\n",
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "print(str(response))\n",
    "print(\"-\" * 88)\n",
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed03229-9aa6-4d3e-befd-f9341257e4ce",
   "metadata": {},
   "source": [
    "### 3.6、封装函数\n",
    "\n",
    "最后我们将前面的部分构建成一个函数`vector_query`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306807f6-c383-4d2b-91ac-1cb989cc7578",
   "metadata": {},
   "source": [
    "本教程的最后一节将这个整体检索工具包装成一个函数。这个函数接受查询字符串和页码作为过滤器。**LLM 实际上可以推断要过滤用户查询的页码，而不是让用户手动指定元数据过滤器**。\n",
    "\n",
    "这里需要注意的是，元数据其实不仅限于页码。**您可以通过 LlamaIndex 抽象定义任何想要的元数据**，如节 IDs、页眉、页脚或其他任何内容。使用许多元数据过滤器的能力在 GPT-4 等更好的大语言模型中尤为突出，因此我们强烈建议读者自行实践一下。\n",
    "\n",
    "这里我们将定义一个封装它的 Python 函数。我们定义一个名为 **vector_query** 的函数，它接受查询和页码。这允许您对索引执行向量搜索，并指定页码作为元数据过滤器。最后，我们定义了一个向量查询 FunctionTool.from_defaults。因此，我们将 vector_query 函数传递到向量查询工具中，这使得我们可以将其与语言模型一起使用。\n",
    "\n",
    "因此，让我们借助 gpt-3.5-turbo 调用此工具。我们会发现 **LLM 能够推断字符串以及元数据过滤器**。我们在向量查询工具上进行了 predict_and_call，并提示了同样的问题：如第二页所述的 MetaGPT 的高水平结果。在这里我们看到 LLM 能够制定正确的查询（MetaGPT 的高水平结果），以及指定页码（取值为 \"2\"）。结果是我们得到了正确的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63594a7-46ff-47b9-8f68-517e6a502ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "\n",
    "def vector_query(query: str, page_number: int) -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "\n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (int): Filter by set of pages. Leave BLANK if we want to perform a vector search over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "    \"\"\"\n",
    "    print(page_number, type(page_number))\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": str(page_number)}]\n",
    "    print(metadata_dicts)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts, condition=FilterCondition.OR\n",
    "        ),\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(name=\"vector_tool\", fn=vector_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19a31a3-22c3-4fca-ac32-ff3e3d91cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 2, \"query\": \"high-level results of MetaGPT\"}\n",
      "2 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '2'}]\n",
      "=== Function Output ===\n",
      "MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It stands out in handling higher levels of software complexity and offering extensive functionality. In experimental evaluations, MetaGPT achieves a 100% task completion rate, demonstrating robustness and efficiency in terms of time and token costs.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool],\n",
    "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc3418a-021b-4eaa-b1d6-57e0b279a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 2, \"query\": \"MetaGPT \\u7684\\u9ad8\\u6c34\\u5e73\\u7ed3\\u679c\"}\n",
      "2 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '2'}]\n",
      "=== Function Output ===\n",
      "MetaGPT 在代码生成基准测试中取得了新的技术水平，Pass@1 分别为 85.9% 和 87.7%，在处理更高级别的软件复杂性和提供广泛功能方面表现出色。在实验评估中，MetaGPT 实现了 100% 的任务完成率，展示了设计的稳健性和效率。\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "def vector_query(query: str, page_number: int) -> str:\n",
    "    \"\"\"对索引进行向量搜索。\n",
    "\n",
    "    query (str)：要进行嵌入的字符串查询。\n",
    "    page_numbers (int)：按页面集过滤。如果要在所有页面上进行向量搜索，则留空。否则，按指定的页面集过滤。\n",
    "\n",
    "    \"\"\"\n",
    "    print(page_number, type(page_number))\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": str(page_number)}]\n",
    "    print(metadata_dicts)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts, condition=FilterCondition.OR\n",
    "        ),\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(name=\"vector_tool\", fn=vector_query)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \"第 2 页中描述的 MetaGPT 的高水平结果是什么？请用中文回答。\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f2e18-fc7a-476f-a344-4c4e0aea86bb",
   "metadata": {},
   "source": [
    "我们可以快速验证源节点，可以看到源节点的页面标签，有一个返回的源节点，它的页面标签是 \"2\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c538c019-089e-45fb-93a2-d419e3a1bfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2984818-d4fe-4f5a-8094-461a00b32b39",
   "metadata": {},
   "source": [
    "## 三、与向量检索工具结合起来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd826632-9b6b-48bf-b49b-82a60e77a0c3",
   "metadata": {},
   "source": [
    "最后，我们可以从 2. 路由查询引擎 Router Query Engine 教程中的 router 示例中引入摘要工具，并将其与向量检索工具有机结合起来，创建这个综合的工具选择系统。所以，下面这段代码只是在相同的节点集上设置了一个摘要索引，并用一个摘要工具将其包装起来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18186ba-9cf2-486a-ab24-3777ef0e6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"Useful if you want to get a summary of MetaGPT.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4719ad-66fb-4558-a68a-121cfe774e13",
   "metadata": {},
   "source": [
    "现在我们再次尝试工具调用。这样一来，**LLM 要做的任务略有提高难度**，它不仅要实际选择正确的工具，还要推断函数参数。我们询问论文第 8 页上 MetaGPT 与 ChatDev 的比较情况。我们看到它实际上还是调用了一个向量工具，页码等于 \"8\"，而且它能够给出正确的答案。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c6d1d3c-2116-4ea2-99cb-2a3a2975246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 8, \"query\": \"MetaGPT comparisons with ChatDev\"}\n",
      "8 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '8'}]\n",
      "=== Function Output ===\n",
      "MetaGPT outperforms ChatDev on the SoftwareDev dataset in various metrics. For example, MetaGPT achieves a higher score in executability, takes less time for software generation, uses more tokens but requires fewer tokens to generate one line of code compared to ChatDev. Additionally, MetaGPT demonstrates better performance in code statistics and human revision cost when compared to ChatDev.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c573e-f0d1-4569-ad47-fbad879adefb",
   "metadata": {},
   "source": [
    "我们还可以通过打印出来源节点来验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03154b63-3c04-409a-bbbd-d157db4415a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7716b78f-e4cc-4688-b51b-fa47dd68e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"page_number\": 8, \"query\": \"MetaGPT \\u4e0e ChatDev \\u7684\\u5bf9\\u6bd4\\u5206\\u6790\\u7ed3\\u679c\"}\n",
      "8 <class 'int'>\n",
      "[{'key': 'page_label', 'value': '8'}]\n",
      "=== Function Output ===\n",
      "MetaGPT 在软件开发数据集中几乎在所有指标上均优于 ChatDev。例如，在可执行性方面，MetaGPT 获得了3.75的分数，接近4（完美）。此外，MetaGPT 生成一行代码所需的时间更短（503秒），明显少于 ChatDev。考虑到代码统计和人工修订成本，MetaGPT 也明显优于 ChatDev。虽然 MetaGPT 需要更多的标记（24,613或31,255比19,292多），但只需要126.5/124.3个标记来生成一行代码。相比之下，ChatDev 使用了248.9个标记。这些结果突显了在多个代理之间的协作中 SOP 的好处。\n",
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-01', 'last_modified_date': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"如果您想了解 MetaGPT 的概要，这个工具会很有用。\"),\n",
    ")\n",
    "\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    \"第 8 页描述的 MetaGPT 与 ChatDev 的对比分析结果是什么？必须用中文回答。\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dba95-d0c5-432b-9217-515dab13f38d",
   "metadata": {},
   "source": [
    "最后，我们可以问一个问题，即**这篇论文的摘要是什么**，以显示 LLM 在必要时仍然能够选择摘要工具。我们看到它给出了正确的回应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29c21c9f-9a84-4690-8a0c-8e82c4ef2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"Summary of the MetaGPT paper\"}\n",
      "=== Function Output ===\n",
      "The MetaGPT paper introduces a meta-programming framework that utilizes Standardized Operating Procedures (SOPs) to enhance multi-agent systems based on Large Language Models (LLMs). It focuses on role specialization, structured communication interfaces, and executable feedback mechanisms to improve code generation quality during runtime. The framework involves agents like Product Managers, Architects, Engineers, and QA Engineers, each contributing specialized outputs to efficiently complete software development tasks. Additionally, it introduces the concept of AgentStore for creating and developing agents within the framework. The paper discusses the transformation of abstract requirements into detailed software designs, emphasizing the importance of structured messaging and feedback mechanisms. It addresses challenges such as reducing code hallucinations, utilizing context efficiently, and managing information overload. The system prioritizes user data privacy and security by operating locally, with open-source options available for backends. Ethical considerations like skill obsolescence, transparency, and privacy are also touched upon.\n"
     ]
    }
   ],
   "source": [
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"Useful if you want to get a summary of MetaGPT.\"),\n",
    ")\n",
    "\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool],\n",
    "    \"What is a summary of the MetaGPT paper?\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7153e63-5da6-49f2-a144-d684b38963fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"MetaGPT\"}\n",
      "=== Function Output ===\n",
      "MetaGPT is a meta-programming framework that enhances problem-solving capabilities in multi-agent systems based on Large Language Models (LLMs). It incorporates role specialization, structured communication interfaces, and efficient sharing mechanisms to facilitate collaboration among agents. MetaGPT also utilizes an executable feedback mechanism to improve code generation quality during runtime. In experiments, MetaGPT has shown state-of-the-art performance on various benchmarks, outperforming other frameworks in tasks like code generation and software development. Additionally, MetaGPT is a framework that utilizes natural language programming to generate software applications based on provided prompts and requirements. It simplifies the process of transforming abstract requirements into detailed class and function designs through a specialized division of labor and standard operating procedures workflow. MetaGPT has been shown to outperform other models in terms of generating executable code, with a focus on structured messaging and feedback mechanisms to enhance communication and code execution. The framework also addresses challenges such as efficiently using context, reducing hallucinations in code generation, and managing information overload through a global message pool and subscription mechanism. Furthermore, MetaGPT emphasizes transparency, accountability, privacy, and data security, operating locally to ensure user data privacy and security.\n"
     ]
    }
   ],
   "source": [
    "# 中文\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"如果您想了解 MetaGPT 的概要，这个工具会很有用。\"),\n",
    ")\n",
    "\n",
    "# 发现使用 LlamaIndex 框架，即使是中文 Prompt，仍可能出现不遵循指令的情况。多次调试，输出结果仍是英文。\n",
    "# 因此，感兴趣的读者可以换一篇中文的论文 PDF 来做实验！\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \"用中文输出 MetaGPT 论文的概要。\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a3ed5-1123-401c-9413-bfaf86f26415",
   "metadata": {},
   "source": [
    "## 三、本章小结\n",
    "***\n",
    "\n",
    "🧍🐒🤖 人与大多数动物的根本区别在于人能制造和使用工具。同样地，智能体也能利用各种外部工具来实现功能扩展和效率提升。\n",
    "\n",
    "在本教程中，我们展示了如何使用 LLM 来选择要执行的函数，并推断要传递给函数的参数。通过工具调用，LLM 不仅能够选择合适的工具，还能决定要给工具什么参数。这使得用户能够提出更多问题，并通过工具调用获得比标准 RAG 技术更精确的结果。\n",
    "\n",
    "教程中还展示了如何在向量搜索之上定义一个稍微复杂一点的智能体层。LLM 可以选择向量搜索，并推断元数据过滤器，以返回更精确的搜索结果。最后，我们展示了如何将整体检索工具封装成一个函数，使 LLM 能够推断用户查询的元数据过滤器。而且通过 LlamaIndex 索引抽象，我们还可以定义各种元数据过滤器，如章节 IDs、页码、页眉、页脚等。\n",
    "\n",
    "✨️🎉🚀 那么，**3. 工具调用 Tool Calling** 就到这里啦~ ✨️🎉🚀 \n",
    "\n",
    "🤖 下一章 **4. Building an Agent Reasoning Loop**，我们将向您展示如何构建智能体推理闭环！🤖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029cad8-11b6-45fd-b34b-3dcea38d09fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
